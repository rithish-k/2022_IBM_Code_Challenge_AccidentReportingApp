{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rithish-k/2022_IBM_Code_Challenge_AccidentReportingApp/blob/main/cs480e_2023%2C3f_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "**Due November 12th, 11:59 PM**"
      ],
      "metadata": {
        "id": "tUheapJCOaxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: \\<FILL HERE\\><br>\n",
        "B-Number: \\<FILL HERE\\><br>\n",
        "Email: \\<FILL HERE\\>"
      ],
      "metadata": {
        "id": "26iemMN3qq0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following assignment,\n",
        "you will be implementing functions and their analytical derivatives to train linear classifiers and neural networks on the MNIST dataset.\n",
        "You are allowed and expected to use NumPy.\n",
        "You are not allowed to use PyTorch.\n",
        "\n",
        "Tasks that need to be completed are indicated with a\n",
        "right-pointing triangle (&#9658;)\n",
        "or clearly stated in the experiments section.\n",
        "\n",
        "<!--\n",
        "The experiments section for each classifier also need to be implemented. You should follow the instructions above the cell. You may also add additional cells.\n",
        "-->\n",
        "\n",
        "Cells that need to be run to set up the appropriate infrastructure are indicated with a downward-pointing triangle (&#9660;).\n",
        "Such cells do not need to be modified.\n",
        "Make sure you have run the previous cells before running the current cell, or you may get an error.\n",
        "\n",
        "Submission will be via GitHub Classroom. **You are required to have at least 10 commits for this assignment.**"
      ],
      "metadata": {
        "id": "jqLULe5pxwpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements\n",
        "\n",
        "&#9660;Run the cell below to import the packages needed for the code below.\n",
        "Most other packages are also okay,\n",
        "but you must ask first."
      ],
      "metadata": {
        "id": "Hnw_h7A1Orc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JLEavoS9O9g-"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Backpropagation"
      ],
      "metadata": {
        "id": "VIBNL5SMPMt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Linear Transforms\n",
        "\n",
        "A linear classifier computes a vector of scores for a single sample,\n",
        "with one score for each class.\n",
        "Let $D$ be the number of features and\n",
        "$M$ be the number of classes.\n",
        "Then the score $y_{i,k}$ for the $k$-th class of the $i$-th sample\n",
        "is computed by:\n",
        "\n",
        "$$\n",
        "y_{i,k} = \\sum_{j = 1}^{D} w_{j,k}x_{i,j} + b_k\n",
        "$$\n",
        "\n",
        "where $w_{j,k}$ is the $j$-th weight for the $k$-th class,\n",
        "$x_{i,j}$ is the $j$-th feature for the $i$-th sample,\n",
        "and $b_k$ is the bias term for class $k$.\n",
        "\n",
        "During training,\n",
        "we often group $N$ samples into what is called a *minibatch*,\n",
        "and process the whole minibatch at once.\n",
        "This is more efficient,\n",
        "and also improves the gradient descent convergence.\n",
        "Letting each sample be a row in the $N\\times D$ matrix $X$,\n",
        "we can then write this as\n",
        "\n",
        "$$\n",
        "Y = XW + B\n",
        "$$\n",
        "\n",
        "where $W$ is the $D \\times M$ weight matrix.\n",
        "The weights for each class form a column in $W$.\n",
        "All the biases have been collected into a single matrix $B$.\n",
        "\n",
        "Although the above can work,\n",
        "we can turn it into a single matrix multiplication\n",
        "via the &ldquo;bias trick&rdquo;,\n",
        "which adds an extra dummy feature in the input sample\n",
        "that is always hard-coded to 1,\n",
        "and then adding an extra weight that is the bias term.\n",
        "\n",
        "$$\n",
        "y_{i,k} = \\sum_{j = 1}^{D + 1} w_{j,k}x_{i,j}, \\ \\ \\text{with}\\ \\ x_{i,D+1} = 1\n",
        "$$\n",
        "\n",
        "The scores for a whole minibatch can now be computed via a standard matrix\n",
        "multiplication.\n",
        "\n",
        "$$\n",
        "Y = X'W'\n",
        "$$\n",
        "\n",
        "where $X'$ and $W'$ are the augmented sample and weight matrices.\n",
        "This transformation forms the basis of a linear, fully-connected (also called &ldquo;dense&rdquo;) layer in a neural network."
      ],
      "metadata": {
        "id": "VhFZKNmUXzt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9654; Implement `linear_forward(X, W)` in the cell below to perform the forward pass of\n",
        "a single linear layer on a batch of samples $X$,\n",
        "using the weights from $W$.\n",
        "The matrix $W$ has already had the bias added to it,\n",
        "so $X$ will need to be augmented with the hard-coded 1."
      ],
      "metadata": {
        "id": "KszunLwwRJqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(X, W):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a linear transformation.\n",
        "\n",
        "    Consider a linear layer that accepts inputs with D features,\n",
        "    and has M neurons.  Assume that our minibatch size\n",
        "    is N.  In other words, we wish to process N samples at once.\n",
        "\n",
        "    The input X has shape (N, D) and contains a minibatch of N\n",
        "    samples, where each sample X[i] has shape (D).  Each sample\n",
        "    will be transformed to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - X: A numpy array containing input data, of shape (N, D)\n",
        "    - W: A numpy array of weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, M)\n",
        "    - cache: (X, W)\n",
        "\n",
        "    The returned (X, W) is redundant, but makes the training code\n",
        "    more concise.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    out = None # Initialize the out variable.\n",
        "\n",
        "    #\n",
        "    # PUT YOUR CODE BELOW: Below, implement the linear forward pass. Store the result in out.\n",
        "    # Make sure to do the bias trick!\n",
        "    #\n",
        "    X_bias_trick = np.hstack([X, np.ones((X.shape[0], 1))])\n",
        "    out = np.dot(X_bias_trick, W)\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    cache = (X, W)\n",
        "\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "fsl6QHm_PJdi"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement `linear_backward(d_upstream, cache)` that returns the downstream analytical gradients with respect to $X$ and $W$,\n",
        "given the upstream gradients and $X$ and $W$.\n",
        "See here for details on how to [backpropagate through a linear layer.](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)"
      ],
      "metadata": {
        "id": "VLnk9xwpRf2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - X: Input data, of shape (N, D)\n",
        "      - W: Weights, of shape (D+1, M)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient of the output of this layer with respect to X, of shape (N, D).\n",
        "          This is the downstream gradient.\n",
        "    - dW: Gradient with respect to W, of shape (D+1, M)\n",
        "    \"\"\"\n",
        "    X, W = cache\n",
        "    dX, dW = None, None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the linear backward pass by calculating the\n",
        "    # gradient with respect to the cached inputs X and W. Store them in the\n",
        "    # variables dX and dW.\n",
        "    X_bias_trick = np.hstack([X, np.ones((X.shape[0], 1))])\n",
        "    dX = np.dot(d_upstream, W[:-1].T)\n",
        "    dW = np.dot(X_bias_trick.T, d_upstream)\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    return dX, dW"
      ],
      "metadata": {
        "id": "41ac6dd5TSEX"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Checking Gradients with Finite Differences\n",
        "\n",
        "Numerical code can be difficult to debug.\n",
        "The general approach is to compare the answer given\n",
        "by your code to the answer obtained from some other technique.\n",
        "A finite difference is a numerical approximation to the derivative which can be used to check your gradients.\n",
        "Because it is only an approximation,\n",
        "you do not use it for actual training,\n",
        "however.\n",
        "\n",
        "The multi-variate central finite difference for a function $f(x,y)$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial x} = \\frac{f(x+h, y)-f(x-h, y)}{2h}\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  f}{\\partial y} = \\frac{f(x, y+h)-f(x, y-h)}{2h}\n",
        "$$\n",
        "\n",
        "The above pattern holds for functions with higher number of variables.\n",
        "For our purposes,\n",
        "an $h$ of about $10^{-9}$ should be adequate."
      ],
      "metadata": {
        "id": "lk1XRA9LSKml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; In the next cell,\n",
        "implement the `finite_difference_linear(d_upstream, cache, h)` function.\n",
        "This function is analogous to `linear_backward()`\n",
        "in that it computes the derivative matrices\n",
        "$\\frac{\\partial L}{\\partial X}$ and\n",
        "$\\frac{\\partial L}{\\partial W}$,\n",
        "given an upstream gradient,\n",
        "but it actually estimates the local gradient\n",
        "using a finite difference.\n",
        "The `h` parameter corresponds to $h$ above;\n",
        "the other parameters are the same as for `linear_backward()`.\n",
        "\n",
        "Recall that the downstream gradient can be computed from\n",
        "the local gradient and upstream gradient by applying the\n",
        "chain rule.\n",
        "In this case,\n",
        "we need the multivariable chain rule,\n",
        "because the loss is a function of the matrix $Y$,\n",
        "and $Y$ is a function of the matrices $X$ and $W$.\n",
        "(Any non-singleton matrix is multivariable by definition.)\n",
        "In particular,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_{i,j}}\n",
        "= \\sum^{N}_{k=1}\\sum^{M}_{l=1} \\frac{\\partial L}{\\partial y_{k,l}}\n",
        "\\frac{\\partial y_{k,l}}{\\partial x_{i,j}}\n",
        "$$\n",
        "\n",
        "where the $\\frac{\\partial L}{\\partial y_{k,l}}$ form the upstream\n",
        "gradient and the $\\frac{\\partial y_{k,l}}{\\partial x_{i,j}}$ form the local gradient.\n",
        "(Note that $\\frac{\\partial y_{k,l}}{\\partial x_{i,j}} = 0$ in our case when $k \\neq i$,\n",
        "because a given sample does not affect the output for other samples\n",
        "in the same minibatch.\n",
        "This fact could be used to optimize the code,\n",
        "but there is no requirement to do so for this assignment.)\n",
        "This simplifies nicely as the gradient for each variable in the matrix is the sum of the products of each upstream partial derivative\n",
        "$\\frac{\\partial L}{\\partial y_{k,l}}$\n",
        "from `d_upstream` and the corresponding element in the finite difference matrix.\n",
        "(This operation is analogous to the dot product,\n",
        "except it is performed on matrices instead of vectors,\n",
        "and is called the\n",
        "[Frobenius product](https://en.wikipedia.org/wiki/Frobenius_inner_product).)"
      ],
      "metadata": {
        "id": "Je8LC4OnT-rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finite_difference_linear(d_upstream, cache, h):\n",
        "    '''\n",
        "    Computes the numerical gradient for a linear layer\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, M)\n",
        "    - cache: Tuple of:\n",
        "      - X: Input data, of shape (N, D)\n",
        "      - W: Weights, of shape (D+1, M)\n",
        "    - h: The h to use in the finite difference.\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dX: Gradient with respect to X, of shape (N, D).  This is the downstream\n",
        "          gradient.\n",
        "    - dW: Gradient with respect to W, of shape (D+1, M)\n",
        "    '''\n",
        "\n",
        "    dX = None\n",
        "    dW = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the finite difference for the linear\n",
        "    # function.  Return the gradient at input (X,W) w.r.t to x and w.\n",
        "    X, W = cache  # Unpack the cached values\n",
        "    N, D = X.shape\n",
        "    M = W.shape[1]\n",
        "\n",
        "    dX = np.zeros((N, D))\n",
        "    dW = np.zeros((D + 1, M))\n",
        "\n",
        "    # Iterate over each element in X and W to compute finite differences\n",
        "    for i in range(N):\n",
        "        for j in range(D):\n",
        "            X_plus_h = X.copy()\n",
        "            X_minus_h = X.copy()\n",
        "\n",
        "            X_plus_h[i, j] += h\n",
        "            X_minus_h[i, j] -= h\n",
        "\n",
        "            X_bias_trick_plus_h = np.hstack([X_plus_h, np.ones((N, 1))])\n",
        "            X_bias_trick_minus_h = np.hstack([X_minus_h, np.ones((N, 1))])\n",
        "            scores_plus_h = np.dot(X_bias_trick_plus_h, W)\n",
        "            scores_minus_h = np.dot(X_bias_trick_minus_h, W)\n",
        "\n",
        "            loss_plus_h = np.sum(scores_plus_h * d_upstream)\n",
        "            loss_minus_h = np.sum(scores_minus_h * d_upstream)\n",
        "\n",
        "            dX[i, j] = (loss_plus_h - loss_minus_h) / (2 * h)\n",
        "\n",
        "    for j in range(D + 1):\n",
        "        for k in range(M):\n",
        "            W_plus_h = W.copy()\n",
        "            W_minus_h = W.copy()\n",
        "\n",
        "            W_plus_h[j, k] += h\n",
        "            W_minus_h[j, k] -= h\n",
        "\n",
        "            X_bias_trick_plus_h = np.hstack([X, np.ones((N, 1))])\n",
        "            X_bias_trick_minus_h = np.hstack([X, np.ones((N, 1))])\n",
        "\n",
        "            scores_plus_h = np.dot(X_bias_trick_plus_h, W_plus_h)\n",
        "            scores_minus_h = np.dot(X_bias_trick_minus_h, W_minus_h)\n",
        "\n",
        "            loss_plus_h = np.sum(scores_plus_h * d_upstream)\n",
        "            loss_minus_h = np.sum(scores_minus_h * d_upstream)\n",
        "\n",
        "            dW[j, k] = (loss_plus_h - loss_minus_h) / (2 * h)\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return dX, dW"
      ],
      "metadata": {
        "id": "HvUDtyAWUx7u"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run this cell to do a gradient check to test the analytical gradients from the `linear_backward()` function with `finite_difference_linear()`."
      ],
      "metadata": {
        "id": "iTNHRnDDvCMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_check_linear():\n",
        "    N = 16\n",
        "    D = 4\n",
        "    C = 3\n",
        "\n",
        "    test_weight = np.random.random((D+1, C))\n",
        "    test_input = np.random.random((N, D))\n",
        "    dout = np.random.random((N, C))\n",
        "\n",
        "    cache = (test_input, test_weight)\n",
        "\n",
        "    grad_x_numerical, grad_w_numerical = finite_difference_linear(dout, cache, 1E-9)\n",
        "    grad_x_analytical, grad_w_analytical = linear_backward(dout, cache)\n",
        "\n",
        "    check_input_gradient = np.allclose(grad_x_numerical, grad_x_analytical)\n",
        "    check_weight_gradient = np.allclose(grad_w_numerical, grad_w_analytical)\n",
        "\n",
        "    if not check_input_gradient:\n",
        "        print(\"The gradient with respect to x failed\")\n",
        "\n",
        "    if not check_weight_gradient:\n",
        "        print(\"The gradient respect to w failed\")\n",
        "    print()\n",
        "    print(\"gradient check for linear passed!\")\n",
        "\n",
        "gradient_check_linear()"
      ],
      "metadata": {
        "id": "jvmbfkfRPSZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e608963-4392-4c9c-8df8-40ff2134f9bc"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient with respect to x failed\n",
            "\n",
            "gradient check for linear passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Linear Classifiers\n",
        "\n",
        "In this section,\n",
        "we will build upon the previously implemented layer to\n",
        "create linear classifiers.\n",
        "We will train them on high-dimensional real world data."
      ],
      "metadata": {
        "id": "i1DiweHpU-_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 MNIST Dataset\n",
        "\n",
        "The dataset we will use is MNIST,\n",
        "a set of images of handwritten digits compiled by the National Institute of Standards and Technology (NIST).\n",
        "This dataset is widely used as a an example for machine learning algorithms for image classification.\n",
        "The images are 28x28 pixels with a single grayscale channel ranging from 0 to 255.\n",
        "\n",
        "Data sets are typically split into\n",
        "[training, validation, and test sets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets).\n",
        "The training set is used to adjust the weights in the model via\n",
        "gradient descent.\n",
        "The validation set is used during training to evaluate\n",
        "the progress of the training,\n",
        "and thus to\n",
        "[select the best model](https://en.wikipedia.org/wiki/Model_selection).\n",
        "The gradient is not computed when using the validation set,\n",
        "thus it does not take part in the gradient descent.\n",
        "The test set is used to evaluate\n",
        "the final results after training.\n",
        "The distinction between the\n",
        "validation and test set is that the validation set\n",
        "can be used to adjust hyperparameters (such as learning rate and model size),\n",
        "and to prevent overfitting, etc.,\n",
        "but the test set cannot be used except to evaluate the final results.\n",
        "\n",
        "You will be using 20,000 samples from the original training dataset for our next set of experiments,\n",
        "and the 10,000 sample test set."
      ],
      "metadata": {
        "id": "38HrO_eBXjrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define some helper functions for loading the MNIST data."
      ],
      "metadata": {
        "id": "dU3af5u3vY2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads and parses CSV file.\n",
        "# Returns a 2-D array containing the images, and a 1-D array\n",
        "# with the labels.  In the image array,\n",
        "# each row is an image.  Pixel values are from 0 to 255.\n",
        "def mnist_data_parser_helper(csv_file_name):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(csv_file_name,'r') as _file:\n",
        "        csv_reader = csv.reader(_file, delimiter=\",\")\n",
        "        for row in csv_reader:\n",
        "            Y.append(float(row[0]))\n",
        "            X.append([float(i) for i in row[1:]])\n",
        "    return (np.array(X), np.array(Y))\n",
        "\n",
        "def get_mnist_train_data():\n",
        "    X_train, Y_train = mnist_data_parser_helper(\"sample_data/mnist_train_small.csv\")\n",
        "    return X_train, Y_train\n",
        "\n",
        "def get_mnist_test_data():\n",
        "    X_test, Y_test = mnist_data_parser_helper(\"sample_data/mnist_test.csv\")\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "y6p9vHGhfBzg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to visualize some samples from the MNIST dataset."
      ],
      "metadata": {
        "id": "nsEncnA3vh9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()\n",
        "\n",
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "classes = list(range(10))\n",
        "\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train.astype('uint8') == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(x_train[idx].astype('uint8').reshape(28,28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "21II-zCpe-ER",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "25f514fd-4630-4ffd-9d24-4c0e42b35901"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 70 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to gather the training and testing dataset.\n"
      ],
      "metadata": {
        "id": "SLbwp3V-vxg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_mnist_train_data()  # Get the training dataset\n",
        "x_test, y_test = get_mnist_test_data()     # Get the test dataset"
      ],
      "metadata": {
        "id": "ZY8RrHx4Fegk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following to normalize the input dataset to have a mean of 0 and standard deviation of 1."
      ],
      "metadata": {
        "id": "d4cTK2RDv5wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = (x_train - x_mean)/(x_std)\n",
        "x_test = (x_test - x_mean)/(x_std)"
      ],
      "metadata": {
        "id": "n7RKsVNmfTx7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to check the dimensions of the data."
      ],
      "metadata": {
        "id": "LfRlRMS9PTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, dim = x_train.shape\n",
        "N_test, _ = x_test.shape\n",
        "print(f\"Number of training sample {N} with {dim} pixels per image\")\n",
        "print(f\"Number of training sample {N_test} with {dim} pixels per image\")"
      ],
      "metadata": {
        "id": "59jB-sjwQNVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d726b6-190b-461b-9860-4484c5afb76b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sample 20000 with 784 pixels per image\n",
            "Number of training sample 10000 with 784 pixels per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Put code in the following cell to split the `x_train` and `y_train` arrays to training and validations sets with an 80-20 split ratio. Place the split arrays in to the `DATA` dictionary. This dictionary will be used to feed data into the `Solver`."
      ],
      "metadata": {
        "id": "QEggmFxlkHYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "y_train = y_train.ravel()\n",
        "y_val = y_val.ravel()\n",
        "DATA = {\n",
        "    \"X_train\": X_train,\n",
        "    \"X_val\": X_val,\n",
        "    \"y_train\": y_train,\n",
        "    \"y_val\": y_val\n",
        "}\n"
      ],
      "metadata": {
        "id": "-ZUHh5UJkHYV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Implement and Evaluate ML Models\n",
        "\n",
        "We will follow a common organization for our code implementation.\n",
        "The `Solver` class is used to orchestrate the\n",
        "overall training steps,\n",
        "such as loading the data,\n",
        "doing the forward pass,\n",
        "computing the gradients with\n",
        "the backward pass,\n",
        "and updating the weights.\n",
        "The `Solver` class\n",
        "uses a *model*\n",
        "object which contains the actual weights,\n",
        "and implements the forward and backward passes."
      ],
      "metadata": {
        "id": "TDV7xaD_BkEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the stochastic gradient descent algorithm that we will use to optimize our models."
      ],
      "metadata": {
        "id": "xXdYUcfTa78v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(w, dw, lr=1e-2):\n",
        "    \"\"\"\n",
        "    Performs vanilla stochastic gradient descent.\n",
        "\n",
        "    config format:\n",
        "    - learning_rate: Scalar learning rate.\n",
        "    \"\"\"\n",
        "\n",
        "    w -= lr * dw\n",
        "    return w"
      ],
      "metadata": {
        "id": "elsI_qFOa8HB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the `Solver` class."
      ],
      "metadata": {
        "id": "DyQdB2T4r9No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    \"\"\"\n",
        "    Solver class for the learnable models using\n",
        "    mini-batch gradient descent.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 data,\n",
        "                 learning_rate=1e-3,\n",
        "                 num_epochs=50,\n",
        "                 batch_size=200,\n",
        "                 validation_frequency=16):\n",
        "        \"\"\"\n",
        "        Construct a new Solver instance.\n",
        "\n",
        "        Inputs:\n",
        "          model: Python class equiped with forward, backward, predict methods and a params dictionary\n",
        "          data: Dictionary with X_train, X_val,  Y_train, Y_val keys\n",
        "          learning_rate: Float, step size of the optimizer\n",
        "          num_epochs: Int, Number of times to completely traverse X_train\n",
        "          batch_size: Int, The number of samples in update\n",
        "          validation_frequency: Int, Solver performs validation loop every validation_frequency batches.\n",
        "                               Set this to a high number if num_epochs is large\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.validation_frequency = validation_frequency\n",
        "\n",
        "        self.num_training = data[\"X_train\"].shape[0]\n",
        "        self.input_dim = data[\"X_train\"].shape[1]\n",
        "\n",
        "        intervals = list(range(0, self.num_training, batch_size))[1:]\n",
        "\n",
        "        self.X_train = np.array_split(data[\"X_train\"], intervals, axis=0)\n",
        "        self.y_train = np.array_split(data[\"y_train\"], intervals)\n",
        "\n",
        "        self.num_batches_in_training = len(self.X_train)\n",
        "\n",
        "        self.X_val = data[\"X_val\"]\n",
        "        self.y_val = data[\"y_val\"]\n",
        "\n",
        "        self.update_rule = sgd\n",
        "        self.loss_history = []\n",
        "        self.validation_history = []\n",
        "\n",
        "        self.iteration_num = 0\n",
        "\n",
        "\n",
        "    def _step(self, batch_id):\n",
        "        \"\"\"\n",
        "        Make a single gradient update. This is called by train() and should not\n",
        "        be called manually.\n",
        "        \"\"\"\n",
        "        # Make a minibatch of training data\n",
        "        X_batch = self.X_train[batch_id]\n",
        "        y_batch = self.y_train[batch_id]\n",
        "\n",
        "        # Compute loss and gradient\n",
        "        score, cache = self.model.forward(X_batch)\n",
        "        loss, dL = self.model.loss(score, y_batch)\n",
        "        _, grads = self.model.backward(dL, cache)\n",
        "\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # Perform a parameter update\n",
        "        for p, w in self.model.params.items():\n",
        "            if p in grads:\n",
        "                dw = grads[p]\n",
        "                next_w = self.update_rule(w, dw, self.learning_rate)\n",
        "                self.model.params[p] = next_w\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Optimization to train the model\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for batch_id in range(self.num_batches_in_training):\n",
        "\n",
        "                self._step(batch_id)\n",
        "\n",
        "                self.iteration_num += 1\n",
        "\n",
        "                if (self.iteration_num % self.validation_frequency == 0):\n",
        "                    self.validate()\n",
        "\n",
        "        self.validate()\n",
        "\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"\n",
        "        Checks the validation error of the model at the time it is being called.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.y_val.shape[0]\n",
        "        predictions = self.model.predict(self.X_val)\n",
        "\n",
        "        accuracy = np.count_nonzero(predictions == self.y_val.astype(int))\n",
        "\n",
        "        print(f\"The validation accuracy at iteration {self.iteration_num}  is \\\n",
        "              {(float(accuracy)/N)*100}%\")"
      ],
      "metadata": {
        "id": "kQP6qra2bpOL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement two different classifiers for the (MNIST) dataset.\n",
        "(A classifier is a kind of model.)\n",
        "The models will both be linear,\n",
        "but will use different loss functions.\n",
        "The first will use the multiclass SVM loss,\n",
        "and the second will use the softmax  loss.\n",
        "\n",
        "The classifiers will be implemented using a common base class\n",
        "that implements training and prediction methods shared by the linear classifiers.\n",
        "Each of the two linear classifiers will be then derive\n",
        "from the base class,\n",
        "but override the loss function."
      ],
      "metadata": {
        "id": "vZfssCcKavEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; In the following cell,\n",
        "complete the definition of the `LinearClassifier` class\n",
        "by implementing the `__init__()`, `forward()`, `backward()`, and `predict()` methods.\n",
        "\n",
        "- The `__init__()` method initializes the class. You must generate a random weight matrix of shape `(input_dim+1, num_classes)`  \n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` transformation on the inputs `x` and weights matrix `self.params['W1']`\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` method.\n",
        "Make sure the key for the returned dictionary `weights_gradient` matches the `self.params` dictionary.\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method."
      ],
      "metadata": {
        "id": "y4b6y_Oj1qr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearClassifier(object):\n",
        "\n",
        "    def __init__(self, input_dim=784, num_classes=10):\n",
        "        self.params = {}\n",
        "        self.input_features = input_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Initialize the weights of the linear classifier with random values\n",
        "        self.params['W1'] = 1e-3 * np.random.randn(input_dim + 1, num_classes)\n",
        "        self.params['b1'] = np.zeros(num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_train, dim = x.shape\n",
        "        num_classes = self.num_classes\n",
        "        out = None\n",
        "        cache = None\n",
        "\n",
        "        # Add an extra column of ones for the bias term\n",
        "        x_with_bias = np.hstack((x, np.ones((num_train, 1))))\n",
        "\n",
        "        # Compute the scores (raw class scores) for each sample in x\n",
        "        scores = np.dot(x_with_bias, self.params['W1']) + self.params['b1']\n",
        "\n",
        "        # Store the scores in 'out' and any relevant values in 'cache'\n",
        "\n",
        "        return scores, cache\n",
        "\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        weight_gradients = {}\n",
        "        dx = None\n",
        "\n",
        "        # Unpack the cache\n",
        "        x_with_bias = cache  # Assuming that the cache contains x_with_bias\n",
        "\n",
        "        if cache is not None:\n",
        "            dx = np.dot(dout, self.params['W1'].T)\n",
        "            weight_gradients['W1'] = np.dot(x_with_bias.T, dout)\n",
        "\n",
        "            # Calculate the gradient for the bias term\n",
        "            weight_gradients['b1'] = np.sum(dout, axis=0)\n",
        "        else:\n",
        "            pass  # Handle the case where cache is None as needed.\n",
        "\n",
        "        return dx, weight_gradients\n",
        "\n",
        "    def predict(self, x):\n",
        "        num_samples, dim = x.shape\n",
        "        num_classes = self.num_classes\n",
        "\n",
        "        # Add an extra column of ones for the bias term\n",
        "        x_with_bias = np.hstack((x, np.ones((num_samples, 1))))\n",
        "\n",
        "        y_pred = np.argmax(np.dot(x_with_bias, self.params['W1']), axis=1)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "oLgT_g66T71G"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Support Vector Machine\n",
        "\n",
        "The `LinearSVM` class defines an SVM-based linear classifier. The classifier uses the hinge loss to optimize the model parameters.\n",
        "The multiclass hinge loss for an input sample $x_i$ (a vector) is given by:\n",
        "\n",
        "$$\n",
        "L_i = \\sum_{j \\neq y_i} \\text{max}(0, s_j-s_{y_i}+1)\n",
        "$$\n",
        "\n",
        "Where, $y_i$ is the label of the $i$-th sample.\n",
        "The label is the correct class label where $0 \\leq y_i \\lt C$,\n",
        "where C is the number of classes.\n",
        "The scalar $s_{y_i}$ is the $y_i$-th element of the score vector.\n",
        "\n",
        "The average loss over N samples is therefore:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{N}\\sum^{N}_{i=1}L_i\n",
        "$$\n",
        "\n",
        "The per-sample gradient of the loss w.r.t. the score $s_j$ is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial  L_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "0 & s_j-s_{y_i}+1 \\leq 0    \\\\\n",
        "1 & j \\neq s_{y_i} \\text{ and } s_j-s_{y_i}+1 > 0 \\\\\n",
        "-\\sum_{i \\neq j}\\frac{\\partial L_i}{\\partial s_i} & j = s_{y_i}\n",
        "\\end{array}\n",
        "\\right..\n",
        "$$"
      ],
      "metadata": {
        "id": "rS6qcaqUcyqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the `svm_loss(scores, y_batch)` function in the following cell.\n",
        "Store the average loss the `loss` variable and the gradient w.r.t `scores` in the `dy` variable.\n",
        "This is the loss over multiple samples, therefore you should take the mean of the loss."
      ],
      "metadata": {
        "id": "fVJxsGOYTgxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_loss(scores, y_batch):\n",
        "    \"\"\"\n",
        "    Returns hinge loss of the scores and y_batch.\n",
        "\n",
        "    Inputs:\n",
        "    - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "      data points; each point has dimension C, where C is the number of classes.\n",
        "    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "    - reg: (float) regularization strength.\n",
        "\n",
        "    Returns: A tuple containing:\n",
        "    - loss as a single float\n",
        "    - gradient with respect to scores; an array of the same shape as scores\n",
        "    \"\"\"\n",
        "    num_samples = scores.shape[0]\n",
        "    loss = 0\n",
        "    dy = np.zeros(scores.shape)\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the structured SVM loss, storing the\n",
        "    # result in loss. Make sure to take the mean of the loss.\n",
        "    # Hint: The intermediate results maybe useful for the gradient calculation\n",
        "\n",
        "\n",
        "    y_batch = y_batch.astype(int)  # Convert y_batch to integer type\n",
        "\n",
        "    correct_class_scores = scores[np.arange(num_samples), y_batch]\n",
        "    margins = np.maximum(0, scores - correct_class_scores[:, np.newaxis] + 1)\n",
        "    margins[np.arange(num_samples), y_batch] = 0\n",
        "\n",
        "    loss = np.sum(margins) / num_samples\n",
        "\n",
        "    num_positive_margins = np.sum(margins > 0, axis=1)\n",
        "    dy = np.zeros_like(scores)\n",
        "    dy[margins > 0] = 1\n",
        "    dy[np.arange(num_samples), y_batch] -= num_positive_margins\n",
        "\n",
        "    loss /= num_samples\n",
        "    dy /= num_samples\n",
        "\n",
        "    # PUT YOUR CODE BELOW:\n",
        "    # Implement the gradient for the SVM loss, storing the result\n",
        "    # in dy.\n",
        "    #\n",
        "    # Hint: Instead of computing the gradient from scratch, it may be easier\n",
        "    # to reuse some of the intermediate values that you used to compute the\n",
        "    # loss.\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "    return loss, dy"
      ],
      "metadata": {
        "id": "S-_mC08N89UC"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660; Run the following cell to define the `LinearSVM` class with your implementation of the `svm_loss`"
      ],
      "metadata": {
        "id": "MMaObHBhamT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearSVM(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Multiclass SVM loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return svm_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "VD43ltPTcw-B"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1.1 SVM Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with SVM models on the training and validation data you've defined previously. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "As you have seen with previous assignments, optimizations can be highly dependent on the hyperparameters of the model. You should try multiple models with different learning rates. You may also increase the amount of time you train by increasing the number of epochs.\n",
        "\n",
        "Keep the top 5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "DNPZ7RoU2Oyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement hyperparameter validation loop in the next cell to train multiple models with different hyperparameters.\n",
        "Keep the top 5 best performing models on the validation set.\n",
        "You can try different learning rates.\n",
        "You may change the num_epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "DD7et1xEF9h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = []\n",
        "learning_rates = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    model = LinearSVM(input_dim=784, num_classes=10)\n",
        "    solver = Solver(\n",
        "        model,\n",
        "        data=DATA,\n",
        "        learning_rate=learning_rate,\n",
        "        num_epochs=num_epochs,\n",
        "        batch_size=50,\n",
        "        validation_frequency=100\n",
        "    )\n",
        "    solver.train()\n",
        "    val_accuracy = np.mean(solver.model.predict(DATA['X_val']) == DATA['y_val'].astype(int))\n",
        "    best_models.append((model, learning_rate, val_accuracy))\n",
        "    best_models.sort(key=lambda x: -x[2])\n",
        "    best_models = best_models[:5]\n",
        "\n",
        "# Print the top 5 best models and their validation accuracies\n",
        "for idx, (best_model, lr, val_accuracy) in enumerate(best_models, start=1):\n",
        "    print(f\"Top {idx} Model: Learning Rate = {lr}, Validation Accuracy = {val_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "US364cOjGC5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7794dbc7-4f47-4352-bab4-6e2f5713ac70"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy at iteration 100  is               8.85%\n",
            "The validation accuracy at iteration 200  is               8.85%\n",
            "The validation accuracy at iteration 300  is               8.85%\n",
            "The validation accuracy at iteration 400  is               8.85%\n",
            "The validation accuracy at iteration 500  is               8.85%\n",
            "The validation accuracy at iteration 600  is               8.85%\n",
            "The validation accuracy at iteration 700  is               8.85%\n",
            "The validation accuracy at iteration 800  is               8.85%\n",
            "The validation accuracy at iteration 900  is               8.85%\n",
            "The validation accuracy at iteration 1000  is               8.85%\n",
            "The validation accuracy at iteration 1100  is               8.85%\n",
            "The validation accuracy at iteration 1200  is               8.85%\n",
            "The validation accuracy at iteration 1300  is               8.85%\n",
            "The validation accuracy at iteration 1400  is               8.85%\n",
            "The validation accuracy at iteration 1500  is               8.85%\n",
            "The validation accuracy at iteration 1600  is               8.85%\n",
            "The validation accuracy at iteration 1700  is               8.85%\n",
            "The validation accuracy at iteration 1800  is               8.85%\n",
            "The validation accuracy at iteration 1900  is               8.85%\n",
            "The validation accuracy at iteration 2000  is               8.85%\n",
            "The validation accuracy at iteration 2100  is               8.85%\n",
            "The validation accuracy at iteration 2200  is               8.85%\n",
            "The validation accuracy at iteration 2300  is               8.85%\n",
            "The validation accuracy at iteration 2400  is               8.85%\n",
            "The validation accuracy at iteration 2500  is               8.85%\n",
            "The validation accuracy at iteration 2600  is               8.85%\n",
            "The validation accuracy at iteration 2700  is               8.85%\n",
            "The validation accuracy at iteration 2800  is               8.85%\n",
            "The validation accuracy at iteration 2900  is               8.85%\n",
            "The validation accuracy at iteration 3000  is               8.85%\n",
            "The validation accuracy at iteration 3100  is               8.85%\n",
            "The validation accuracy at iteration 3200  is               8.85%\n",
            "The validation accuracy at iteration 3200  is               8.85%\n",
            "The validation accuracy at iteration 100  is               12.45%\n",
            "The validation accuracy at iteration 200  is               12.45%\n",
            "The validation accuracy at iteration 300  is               12.45%\n",
            "The validation accuracy at iteration 400  is               12.45%\n",
            "The validation accuracy at iteration 500  is               12.45%\n",
            "The validation accuracy at iteration 600  is               12.45%\n",
            "The validation accuracy at iteration 700  is               12.45%\n",
            "The validation accuracy at iteration 800  is               12.45%\n",
            "The validation accuracy at iteration 900  is               12.45%\n",
            "The validation accuracy at iteration 1000  is               12.45%\n",
            "The validation accuracy at iteration 1100  is               12.45%\n",
            "The validation accuracy at iteration 1200  is               12.45%\n",
            "The validation accuracy at iteration 1300  is               12.45%\n",
            "The validation accuracy at iteration 1400  is               12.45%\n",
            "The validation accuracy at iteration 1500  is               12.45%\n",
            "The validation accuracy at iteration 1600  is               12.45%\n",
            "The validation accuracy at iteration 1700  is               12.45%\n",
            "The validation accuracy at iteration 1800  is               12.45%\n",
            "The validation accuracy at iteration 1900  is               12.45%\n",
            "The validation accuracy at iteration 2000  is               12.45%\n",
            "The validation accuracy at iteration 2100  is               12.45%\n",
            "The validation accuracy at iteration 2200  is               12.45%\n",
            "The validation accuracy at iteration 2300  is               12.45%\n",
            "The validation accuracy at iteration 2400  is               12.45%\n",
            "The validation accuracy at iteration 2500  is               12.45%\n",
            "The validation accuracy at iteration 2600  is               12.45%\n",
            "The validation accuracy at iteration 2700  is               12.45%\n",
            "The validation accuracy at iteration 2800  is               12.45%\n",
            "The validation accuracy at iteration 2900  is               12.45%\n",
            "The validation accuracy at iteration 3000  is               12.45%\n",
            "The validation accuracy at iteration 3100  is               12.45%\n",
            "The validation accuracy at iteration 3200  is               12.45%\n",
            "The validation accuracy at iteration 3200  is               12.45%\n",
            "The validation accuracy at iteration 100  is               13.525%\n",
            "The validation accuracy at iteration 200  is               13.525%\n",
            "The validation accuracy at iteration 300  is               13.525%\n",
            "The validation accuracy at iteration 400  is               13.525%\n",
            "The validation accuracy at iteration 500  is               13.525%\n",
            "The validation accuracy at iteration 600  is               13.525%\n",
            "The validation accuracy at iteration 700  is               13.525%\n",
            "The validation accuracy at iteration 800  is               13.525%\n",
            "The validation accuracy at iteration 900  is               13.525%\n",
            "The validation accuracy at iteration 1000  is               13.525%\n",
            "The validation accuracy at iteration 1100  is               13.525%\n",
            "The validation accuracy at iteration 1200  is               13.525%\n",
            "The validation accuracy at iteration 1300  is               13.525%\n",
            "The validation accuracy at iteration 1400  is               13.525%\n",
            "The validation accuracy at iteration 1500  is               13.525%\n",
            "The validation accuracy at iteration 1600  is               13.525%\n",
            "The validation accuracy at iteration 1700  is               13.525%\n",
            "The validation accuracy at iteration 1800  is               13.525%\n",
            "The validation accuracy at iteration 1900  is               13.525%\n",
            "The validation accuracy at iteration 2000  is               13.525%\n",
            "The validation accuracy at iteration 2100  is               13.525%\n",
            "The validation accuracy at iteration 2200  is               13.525%\n",
            "The validation accuracy at iteration 2300  is               13.525%\n",
            "The validation accuracy at iteration 2400  is               13.525%\n",
            "The validation accuracy at iteration 2500  is               13.525%\n",
            "The validation accuracy at iteration 2600  is               13.525%\n",
            "The validation accuracy at iteration 2700  is               13.525%\n",
            "The validation accuracy at iteration 2800  is               13.525%\n",
            "The validation accuracy at iteration 2900  is               13.525%\n",
            "The validation accuracy at iteration 3000  is               13.525%\n",
            "The validation accuracy at iteration 3100  is               13.525%\n",
            "The validation accuracy at iteration 3200  is               13.525%\n",
            "The validation accuracy at iteration 3200  is               13.525%\n",
            "The validation accuracy at iteration 100  is               7.1%\n",
            "The validation accuracy at iteration 200  is               7.1%\n",
            "The validation accuracy at iteration 300  is               7.1%\n",
            "The validation accuracy at iteration 400  is               7.1%\n",
            "The validation accuracy at iteration 500  is               7.1%\n",
            "The validation accuracy at iteration 600  is               7.1%\n",
            "The validation accuracy at iteration 700  is               7.1%\n",
            "The validation accuracy at iteration 800  is               7.1%\n",
            "The validation accuracy at iteration 900  is               7.1%\n",
            "The validation accuracy at iteration 1000  is               7.1%\n",
            "The validation accuracy at iteration 1100  is               7.1%\n",
            "The validation accuracy at iteration 1200  is               7.1%\n",
            "The validation accuracy at iteration 1300  is               7.1%\n",
            "The validation accuracy at iteration 1400  is               7.1%\n",
            "The validation accuracy at iteration 1500  is               7.1%\n",
            "The validation accuracy at iteration 1600  is               7.1%\n",
            "The validation accuracy at iteration 1700  is               7.1%\n",
            "The validation accuracy at iteration 1800  is               7.1%\n",
            "The validation accuracy at iteration 1900  is               7.1%\n",
            "The validation accuracy at iteration 2000  is               7.1%\n",
            "The validation accuracy at iteration 2100  is               7.1%\n",
            "The validation accuracy at iteration 2200  is               7.1%\n",
            "The validation accuracy at iteration 2300  is               7.1%\n",
            "The validation accuracy at iteration 2400  is               7.1%\n",
            "The validation accuracy at iteration 2500  is               7.1%\n",
            "The validation accuracy at iteration 2600  is               7.1%\n",
            "The validation accuracy at iteration 2700  is               7.1%\n",
            "The validation accuracy at iteration 2800  is               7.1%\n",
            "The validation accuracy at iteration 2900  is               7.1%\n",
            "The validation accuracy at iteration 3000  is               7.1%\n",
            "The validation accuracy at iteration 3100  is               7.1%\n",
            "The validation accuracy at iteration 3200  is               7.1%\n",
            "The validation accuracy at iteration 3200  is               7.1%\n",
            "The validation accuracy at iteration 100  is               10.25%\n",
            "The validation accuracy at iteration 200  is               10.25%\n",
            "The validation accuracy at iteration 300  is               10.25%\n",
            "The validation accuracy at iteration 400  is               10.25%\n",
            "The validation accuracy at iteration 500  is               10.25%\n",
            "The validation accuracy at iteration 600  is               10.25%\n",
            "The validation accuracy at iteration 700  is               10.25%\n",
            "The validation accuracy at iteration 800  is               10.25%\n",
            "The validation accuracy at iteration 900  is               10.25%\n",
            "The validation accuracy at iteration 1000  is               10.25%\n",
            "The validation accuracy at iteration 1100  is               10.25%\n",
            "The validation accuracy at iteration 1200  is               10.25%\n",
            "The validation accuracy at iteration 1300  is               10.25%\n",
            "The validation accuracy at iteration 1400  is               10.25%\n",
            "The validation accuracy at iteration 1500  is               10.25%\n",
            "The validation accuracy at iteration 1600  is               10.25%\n",
            "The validation accuracy at iteration 1700  is               10.25%\n",
            "The validation accuracy at iteration 1800  is               10.25%\n",
            "The validation accuracy at iteration 1900  is               10.25%\n",
            "The validation accuracy at iteration 2000  is               10.25%\n",
            "The validation accuracy at iteration 2100  is               10.25%\n",
            "The validation accuracy at iteration 2200  is               10.25%\n",
            "The validation accuracy at iteration 2300  is               10.25%\n",
            "The validation accuracy at iteration 2400  is               10.25%\n",
            "The validation accuracy at iteration 2500  is               10.25%\n",
            "The validation accuracy at iteration 2600  is               10.25%\n",
            "The validation accuracy at iteration 2700  is               10.25%\n",
            "The validation accuracy at iteration 2800  is               10.25%\n",
            "The validation accuracy at iteration 2900  is               10.25%\n",
            "The validation accuracy at iteration 3000  is               10.25%\n",
            "The validation accuracy at iteration 3100  is               10.25%\n",
            "The validation accuracy at iteration 3200  is               10.25%\n",
            "The validation accuracy at iteration 3200  is               10.25%\n",
            "The validation accuracy at iteration 100  is               9.15%\n",
            "The validation accuracy at iteration 200  is               9.15%\n",
            "The validation accuracy at iteration 300  is               9.15%\n",
            "The validation accuracy at iteration 400  is               9.15%\n",
            "The validation accuracy at iteration 500  is               9.15%\n",
            "The validation accuracy at iteration 600  is               9.15%\n",
            "The validation accuracy at iteration 700  is               9.15%\n",
            "The validation accuracy at iteration 800  is               9.15%\n",
            "The validation accuracy at iteration 900  is               9.15%\n",
            "The validation accuracy at iteration 1000  is               9.15%\n",
            "The validation accuracy at iteration 1100  is               9.15%\n",
            "The validation accuracy at iteration 1200  is               9.15%\n",
            "The validation accuracy at iteration 1300  is               9.15%\n",
            "The validation accuracy at iteration 1400  is               9.15%\n",
            "The validation accuracy at iteration 1500  is               9.15%\n",
            "The validation accuracy at iteration 1600  is               9.15%\n",
            "The validation accuracy at iteration 1700  is               9.15%\n",
            "The validation accuracy at iteration 1800  is               9.15%\n",
            "The validation accuracy at iteration 1900  is               9.15%\n",
            "The validation accuracy at iteration 2000  is               9.15%\n",
            "The validation accuracy at iteration 2100  is               9.15%\n",
            "The validation accuracy at iteration 2200  is               9.15%\n",
            "The validation accuracy at iteration 2300  is               9.15%\n",
            "The validation accuracy at iteration 2400  is               9.15%\n",
            "The validation accuracy at iteration 2500  is               9.15%\n",
            "The validation accuracy at iteration 2600  is               9.15%\n",
            "The validation accuracy at iteration 2700  is               9.15%\n",
            "The validation accuracy at iteration 2800  is               9.15%\n",
            "The validation accuracy at iteration 2900  is               9.15%\n",
            "The validation accuracy at iteration 3000  is               9.15%\n",
            "The validation accuracy at iteration 3100  is               9.15%\n",
            "The validation accuracy at iteration 3200  is               9.15%\n",
            "The validation accuracy at iteration 3200  is               9.15%\n",
            "The validation accuracy at iteration 100  is               8.924999999999999%\n",
            "The validation accuracy at iteration 200  is               8.924999999999999%\n",
            "The validation accuracy at iteration 300  is               8.924999999999999%\n",
            "The validation accuracy at iteration 400  is               8.924999999999999%\n",
            "The validation accuracy at iteration 500  is               8.924999999999999%\n",
            "The validation accuracy at iteration 600  is               8.924999999999999%\n",
            "The validation accuracy at iteration 700  is               8.924999999999999%\n",
            "The validation accuracy at iteration 800  is               8.924999999999999%\n",
            "The validation accuracy at iteration 900  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1000  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1100  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1200  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1300  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1400  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1500  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1600  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1700  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1800  is               8.924999999999999%\n",
            "The validation accuracy at iteration 1900  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2000  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2100  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2200  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2300  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2400  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2500  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2600  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2700  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2800  is               8.924999999999999%\n",
            "The validation accuracy at iteration 2900  is               8.924999999999999%\n",
            "The validation accuracy at iteration 3000  is               8.924999999999999%\n",
            "The validation accuracy at iteration 3100  is               8.924999999999999%\n",
            "The validation accuracy at iteration 3200  is               8.924999999999999%\n",
            "The validation accuracy at iteration 3200  is               8.924999999999999%\n",
            "The validation accuracy at iteration 100  is               9.950000000000001%\n",
            "The validation accuracy at iteration 200  is               9.950000000000001%\n",
            "The validation accuracy at iteration 300  is               9.950000000000001%\n",
            "The validation accuracy at iteration 400  is               9.950000000000001%\n",
            "The validation accuracy at iteration 500  is               9.950000000000001%\n",
            "The validation accuracy at iteration 600  is               9.950000000000001%\n",
            "The validation accuracy at iteration 700  is               9.950000000000001%\n",
            "The validation accuracy at iteration 800  is               9.950000000000001%\n",
            "The validation accuracy at iteration 900  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1000  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1100  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1200  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1300  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1400  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1500  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1600  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1700  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1800  is               9.950000000000001%\n",
            "The validation accuracy at iteration 1900  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2000  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2100  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2200  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2300  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2400  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2500  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2600  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2700  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2800  is               9.950000000000001%\n",
            "The validation accuracy at iteration 2900  is               9.950000000000001%\n",
            "The validation accuracy at iteration 3000  is               9.950000000000001%\n",
            "The validation accuracy at iteration 3100  is               9.950000000000001%\n",
            "The validation accuracy at iteration 3200  is               9.950000000000001%\n",
            "The validation accuracy at iteration 3200  is               9.950000000000001%\n",
            "Top 1 Model: Learning Rate = 1e-05, Validation Accuracy = 13.53%\n",
            "Top 2 Model: Learning Rate = 0.0001, Validation Accuracy = 12.45%\n",
            "Top 3 Model: Learning Rate = 1e-07, Validation Accuracy = 10.25%\n",
            "Top 4 Model: Learning Rate = 1e-10, Validation Accuracy = 9.95%\n",
            "Top 5 Model: Learning Rate = 1e-08, Validation Accuracy = 9.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top 5 performing models on the test set and print the results."
      ],
      "metadata": {
        "id": "Dl4R1tyz4VpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = get_mnist_test_data()\n",
        "x_test = (x_test - x_mean) / (x_std)\n",
        "\n",
        "def test_model(model, x_test, y_test):\n",
        "    predictions = model.predict(x_test)\n",
        "    accuracy = np.mean(predictions == y_test.astype(int))\n",
        "    return accuracy\n",
        "test_accuracies = []\n",
        "\n",
        "for model, lr, _ in best_models:\n",
        "    accuracy = test_model(model, x_test, y_test)\n",
        "    test_accuracies.append(accuracy)\n",
        "\n",
        "for idx, accuracy in enumerate(test_accuracies, start=1):\n",
        "    print(f\"Top {idx} Model Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "71qBuIr75ArL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335e685f-5058-473c-c717-28d7624e68da"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Model Test Accuracy: 14.14%\n",
            "Top 2 Model Test Accuracy: 13.80%\n",
            "Top 3 Model Test Accuracy: 9.46%\n",
            "Top 4 Model Test Accuracy: 9.61%\n",
            "Top 5 Model Test Accuracy: 9.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the next cell to visualize the weights corresponding to each sample in the *best* performing SVM models. You should have ten 28x28 images.\n",
        "\n",
        "Make sure to rescale the  weights to be between 0 and 255.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class.\n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "srNp8XPEbVAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "top_model, _, _ = best_models[0]\n",
        "weights = top_model.params['W1']\n",
        "min_weight = np.min(weights)\n",
        "max_weight = np.max(weights)\n",
        "rescaled_weights = (weights - min_weight) / (max_weight - min_weight) * 255\n",
        "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
        "for i in range(10):\n",
        "    weight_image = rescaled_weights[:, i].reshape(28, 28)\n",
        "    axs[i].imshow(weight_image, cmap='gray')\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(f'Class {i}')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hVDxnLZCbVQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "d07661d3-18d9-410d-c3a6-021b74a97193"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-99ca83125289>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mweight_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescaled_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 785 into shape (28,28)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Cross-Entropy Loss\n",
        "\n",
        "The `CrossEntropy` class defines the cross-entropy loss for training and prediction methods like the previous the linear classifiers.\n",
        "Because the cross-entropy is defined on probability distributions,\n",
        "the softmax function is usually applied to the output of a linear\n",
        "classifier to transform the raw scores into values that can be interpreted as probabilities.\n",
        "(Though, be cautious about actually using them as such.)\n",
        "However,\n",
        "we commonly refer to it just as the cross-entropy loss,\n",
        "with the implicit understanding that for deep learning,\n",
        "the cross-entropy is not computed on the raw scores,\n",
        "but rather the softmax of the raw scores.\n",
        "\n",
        "For a score vector $s$, the softmax activation of the $j$-th element is given by,\n",
        "\n",
        "$$\n",
        "\\sigma_j = \\frac{e^{s_{j}}}{\\sum^{M}_{k=1}e^{s_k}}\n",
        "$$\n",
        "\n",
        "A simple implementation of the softmax function can result in overflow.\n",
        "See\n",
        "[here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/#:~:text=Computing%20softmax%20and%20numerical%20stability)\n",
        "for how to avoid this problem.\n",
        "\n",
        "The cross-entropy is a measure of the difference between two probability distributions.\n",
        "In the general case,\n",
        "the cross-entropy $H$ between the true probability distribution $P$ and the estimated probability distribution $Q$ is given by:\n",
        "\n",
        "$$\n",
        "H(P, Q)=-\\sum_{x \\in \\mathcal{X}} P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "where $\\mathcal{X}$ is the event space.\n",
        "It is a measure of how \"far off\" our estimated distribution $Q$ is from $P$.\n",
        "(Note that because $P$ and $Q$ are actually functions,\n",
        "$H$ in this case is a function operating on functions, also known as an *operator*.)\n",
        "\n",
        "In our case,\n",
        "$P$ is zero except for the correct label,\n",
        "and thus the cross-entropy reduces to simply the negative logarithm of the score corresponding to the correct class,\n",
        "which is just\n",
        "\n",
        "$$\n",
        "L_i = -\\log(\\sigma_{y_i}))\n",
        "$$\n",
        "\n",
        "where $y_i$ is the correct label of the $x_i$ input sample,\n",
        "and $\\sigma_{y_i}$ is the softmax output of the corresponding correct label. $L$ is then just the average over the $L_i$.\n",
        "\n",
        "The derivative of the softmax is given by\n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\sigma_i}{\\partial s_j} = \\left \\{\n",
        "\\begin{array}{ll}\n",
        "\\sigma_i(1 - \\sigma_{j}) & i = j     \\\\\n",
        "-\\sigma_i\\sigma_j & i \\neq j  \\\\\n",
        "\\end{array}\n",
        "\\right. .\n",
        "$$\n",
        "\n",
        "Details on the derivation can be found [here](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/).\n",
        "\n",
        "The derivative of the negative logarithm is given by\n",
        "\n",
        "$$\n",
        "\\frac{\\partial (-\\log)}{\\partial \\sigma_{y_i}} = -\\frac{1}{\\sigma_{y_i}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "nhA92akOczjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the `cross_entropy_loss(scores, y_batch)` function in the following cell,\n",
        "consisting of the softmax followed by cross-entropy,\n",
        "as explained above.\n",
        "The function returns a tuple of `(loss, dy)` where\n",
        "`loss` is the cross-entropy loss based on the inputs\n",
        "and `dy` is the gradient of the loss with respect to the `scores` input.\n",
        "This is the loss over multiple samples,\n",
        "therefore you should take the mean of the loss."
      ],
      "metadata": {
        "id": "XJDqbXH4yxZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(scores, y_batch):\n",
        "    N, C = scores.shape\n",
        "    exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "    y_batch = y_batch.astype(int)\n",
        "    loss = -np.log(probs[np.arange(N), y_batch])\n",
        "    loss = np.mean(loss)\n",
        "    dy = probs\n",
        "    dy[np.arange(N), y_batch] -= 1\n",
        "    dy /= N\n",
        "\n",
        "    return loss, dy\n"
      ],
      "metadata": {
        "id": "5hIEv5fl9llO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9660;\n",
        "Run the following cell to define the `CrossEntropy` classifier class."
      ],
      "metadata": {
        "id": "8h0EQF-yuu8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropy(LinearClassifier):\n",
        "    \"\"\" A subclass that uses the Softmax + Cross-entropy loss function \"\"\"\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "RKYgCIcHczy1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.1 Cross-Entropy Experiments\n",
        "\n",
        "In the next few cells run the `Solver` with softmax models on the training and validation data you've defined previously,\n",
        "similarly to the SVM experiments.\n",
        "Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Keep the top 5 best performing models and the worst performing model on the validation set."
      ],
      "metadata": {
        "id": "Ug02WvIg5DT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the hyperparameter validation loop in the next cell to train multiple models with different hyperparameters.\n",
        "Keep the top 5 best performing models on the validation set.\n",
        "You can try different learning rates.\n",
        "You may change the number of epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "qRFvUnysFwvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = []  # List to store the top 5 best models\n",
        "\n",
        "# Define a range of learning rates to try\n",
        "learning_rates = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 50  # You can adjust this as needed\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    # Create a LinearSVM model with the current learning rate\n",
        "    model = CrossEntropy(input_dim=784, num_classes=10)\n",
        "\n",
        "    # Create a Solver instance\n",
        "    solver = Solver(\n",
        "        model,\n",
        "        data=DATA,\n",
        "        learning_rate=learning_rate,\n",
        "        num_epochs=num_epochs,\n",
        "        batch_size=50,\n",
        "        validation_frequency=100\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    solver.train()\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_accuracy = np.mean(solver.model.predict(DATA['X_val']) == DATA['y_val'].astype(int))\n",
        "\n",
        "    # Store the model, its learning rate, and validation accuracy in a tuple\n",
        "    best_models.append((model, learning_rate, val_accuracy))\n",
        "\n",
        "    # Sort the best_models list based on validation accuracy\n",
        "    best_models.sort(key=lambda x: -x[2])\n",
        "\n",
        "    # Keep only the top 5 best models\n",
        "    best_models = best_models[:5]\n",
        "\n",
        "# Print the top 5 best models and their validation accuracies\n",
        "for idx, (best_model, lr, val_accuracy) in enumerate(best_models, start=1):\n",
        "    print(f\"Top {idx} Model: Learning Rate = {lr}, Validation Accuracy = {val_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "05Od5fTg5Dqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122e7910-bc53-412d-b96b-168988a175bb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The validation accuracy at iteration 100  is               12.575%\n",
            "The validation accuracy at iteration 200  is               12.575%\n",
            "The validation accuracy at iteration 300  is               12.575%\n",
            "The validation accuracy at iteration 400  is               12.575%\n",
            "The validation accuracy at iteration 500  is               12.575%\n",
            "The validation accuracy at iteration 600  is               12.575%\n",
            "The validation accuracy at iteration 700  is               12.575%\n",
            "The validation accuracy at iteration 800  is               12.575%\n",
            "The validation accuracy at iteration 900  is               12.575%\n",
            "The validation accuracy at iteration 1000  is               12.575%\n",
            "The validation accuracy at iteration 1100  is               12.575%\n",
            "The validation accuracy at iteration 1200  is               12.575%\n",
            "The validation accuracy at iteration 1300  is               12.575%\n",
            "The validation accuracy at iteration 1400  is               12.575%\n",
            "The validation accuracy at iteration 1500  is               12.575%\n",
            "The validation accuracy at iteration 1600  is               12.575%\n",
            "The validation accuracy at iteration 1700  is               12.575%\n",
            "The validation accuracy at iteration 1800  is               12.575%\n",
            "The validation accuracy at iteration 1900  is               12.575%\n",
            "The validation accuracy at iteration 2000  is               12.575%\n",
            "The validation accuracy at iteration 2100  is               12.575%\n",
            "The validation accuracy at iteration 2200  is               12.575%\n",
            "The validation accuracy at iteration 2300  is               12.575%\n",
            "The validation accuracy at iteration 2400  is               12.575%\n",
            "The validation accuracy at iteration 2500  is               12.575%\n",
            "The validation accuracy at iteration 2600  is               12.575%\n",
            "The validation accuracy at iteration 2700  is               12.575%\n",
            "The validation accuracy at iteration 2800  is               12.575%\n",
            "The validation accuracy at iteration 2900  is               12.575%\n",
            "The validation accuracy at iteration 3000  is               12.575%\n",
            "The validation accuracy at iteration 3100  is               12.575%\n",
            "The validation accuracy at iteration 3200  is               12.575%\n",
            "The validation accuracy at iteration 3300  is               12.575%\n",
            "The validation accuracy at iteration 3400  is               12.575%\n",
            "The validation accuracy at iteration 3500  is               12.575%\n",
            "The validation accuracy at iteration 3600  is               12.575%\n",
            "The validation accuracy at iteration 3700  is               12.575%\n",
            "The validation accuracy at iteration 3800  is               12.575%\n",
            "The validation accuracy at iteration 3900  is               12.575%\n",
            "The validation accuracy at iteration 4000  is               12.575%\n",
            "The validation accuracy at iteration 4100  is               12.575%\n",
            "The validation accuracy at iteration 4200  is               12.575%\n",
            "The validation accuracy at iteration 4300  is               12.575%\n",
            "The validation accuracy at iteration 4400  is               12.575%\n",
            "The validation accuracy at iteration 4500  is               12.575%\n",
            "The validation accuracy at iteration 4600  is               12.575%\n",
            "The validation accuracy at iteration 4700  is               12.575%\n",
            "The validation accuracy at iteration 4800  is               12.575%\n",
            "The validation accuracy at iteration 4900  is               12.575%\n",
            "The validation accuracy at iteration 5000  is               12.575%\n",
            "The validation accuracy at iteration 5100  is               12.575%\n",
            "The validation accuracy at iteration 5200  is               12.575%\n",
            "The validation accuracy at iteration 5300  is               12.575%\n",
            "The validation accuracy at iteration 5400  is               12.575%\n",
            "The validation accuracy at iteration 5500  is               12.575%\n",
            "The validation accuracy at iteration 5600  is               12.575%\n",
            "The validation accuracy at iteration 5700  is               12.575%\n",
            "The validation accuracy at iteration 5800  is               12.575%\n",
            "The validation accuracy at iteration 5900  is               12.575%\n",
            "The validation accuracy at iteration 6000  is               12.575%\n",
            "The validation accuracy at iteration 6100  is               12.575%\n",
            "The validation accuracy at iteration 6200  is               12.575%\n",
            "The validation accuracy at iteration 6300  is               12.575%\n",
            "The validation accuracy at iteration 6400  is               12.575%\n",
            "The validation accuracy at iteration 6500  is               12.575%\n",
            "The validation accuracy at iteration 6600  is               12.575%\n",
            "The validation accuracy at iteration 6700  is               12.575%\n",
            "The validation accuracy at iteration 6800  is               12.575%\n",
            "The validation accuracy at iteration 6900  is               12.575%\n",
            "The validation accuracy at iteration 7000  is               12.575%\n",
            "The validation accuracy at iteration 7100  is               12.575%\n",
            "The validation accuracy at iteration 7200  is               12.575%\n",
            "The validation accuracy at iteration 7300  is               12.575%\n",
            "The validation accuracy at iteration 7400  is               12.575%\n",
            "The validation accuracy at iteration 7500  is               12.575%\n",
            "The validation accuracy at iteration 7600  is               12.575%\n",
            "The validation accuracy at iteration 7700  is               12.575%\n",
            "The validation accuracy at iteration 7800  is               12.575%\n",
            "The validation accuracy at iteration 7900  is               12.575%\n",
            "The validation accuracy at iteration 8000  is               12.575%\n",
            "The validation accuracy at iteration 8100  is               12.575%\n",
            "The validation accuracy at iteration 8200  is               12.575%\n",
            "The validation accuracy at iteration 8300  is               12.575%\n",
            "The validation accuracy at iteration 8400  is               12.575%\n",
            "The validation accuracy at iteration 8500  is               12.575%\n",
            "The validation accuracy at iteration 8600  is               12.575%\n",
            "The validation accuracy at iteration 8700  is               12.575%\n",
            "The validation accuracy at iteration 8800  is               12.575%\n",
            "The validation accuracy at iteration 8900  is               12.575%\n",
            "The validation accuracy at iteration 9000  is               12.575%\n",
            "The validation accuracy at iteration 9100  is               12.575%\n",
            "The validation accuracy at iteration 9200  is               12.575%\n",
            "The validation accuracy at iteration 9300  is               12.575%\n",
            "The validation accuracy at iteration 9400  is               12.575%\n",
            "The validation accuracy at iteration 9500  is               12.575%\n",
            "The validation accuracy at iteration 9600  is               12.575%\n",
            "The validation accuracy at iteration 9700  is               12.575%\n",
            "The validation accuracy at iteration 9800  is               12.575%\n",
            "The validation accuracy at iteration 9900  is               12.575%\n",
            "The validation accuracy at iteration 10000  is               12.575%\n",
            "The validation accuracy at iteration 10100  is               12.575%\n",
            "The validation accuracy at iteration 10200  is               12.575%\n",
            "The validation accuracy at iteration 10300  is               12.575%\n",
            "The validation accuracy at iteration 10400  is               12.575%\n",
            "The validation accuracy at iteration 10500  is               12.575%\n",
            "The validation accuracy at iteration 10600  is               12.575%\n",
            "The validation accuracy at iteration 10700  is               12.575%\n",
            "The validation accuracy at iteration 10800  is               12.575%\n",
            "The validation accuracy at iteration 10900  is               12.575%\n",
            "The validation accuracy at iteration 11000  is               12.575%\n",
            "The validation accuracy at iteration 11100  is               12.575%\n",
            "The validation accuracy at iteration 11200  is               12.575%\n",
            "The validation accuracy at iteration 11300  is               12.575%\n",
            "The validation accuracy at iteration 11400  is               12.575%\n",
            "The validation accuracy at iteration 11500  is               12.575%\n",
            "The validation accuracy at iteration 11600  is               12.575%\n",
            "The validation accuracy at iteration 11700  is               12.575%\n",
            "The validation accuracy at iteration 11800  is               12.575%\n",
            "The validation accuracy at iteration 11900  is               12.575%\n",
            "The validation accuracy at iteration 12000  is               12.575%\n",
            "The validation accuracy at iteration 12100  is               12.575%\n",
            "The validation accuracy at iteration 12200  is               12.575%\n",
            "The validation accuracy at iteration 12300  is               12.575%\n",
            "The validation accuracy at iteration 12400  is               12.575%\n",
            "The validation accuracy at iteration 12500  is               12.575%\n",
            "The validation accuracy at iteration 12600  is               12.575%\n",
            "The validation accuracy at iteration 12700  is               12.575%\n",
            "The validation accuracy at iteration 12800  is               12.575%\n",
            "The validation accuracy at iteration 12900  is               12.575%\n",
            "The validation accuracy at iteration 13000  is               12.575%\n",
            "The validation accuracy at iteration 13100  is               12.575%\n",
            "The validation accuracy at iteration 13200  is               12.575%\n",
            "The validation accuracy at iteration 13300  is               12.575%\n",
            "The validation accuracy at iteration 13400  is               12.575%\n",
            "The validation accuracy at iteration 13500  is               12.575%\n",
            "The validation accuracy at iteration 13600  is               12.575%\n",
            "The validation accuracy at iteration 13700  is               12.575%\n",
            "The validation accuracy at iteration 13800  is               12.575%\n",
            "The validation accuracy at iteration 13900  is               12.575%\n",
            "The validation accuracy at iteration 14000  is               12.575%\n",
            "The validation accuracy at iteration 14100  is               12.575%\n",
            "The validation accuracy at iteration 14200  is               12.575%\n",
            "The validation accuracy at iteration 14300  is               12.575%\n",
            "The validation accuracy at iteration 14400  is               12.575%\n",
            "The validation accuracy at iteration 14500  is               12.575%\n",
            "The validation accuracy at iteration 14600  is               12.575%\n",
            "The validation accuracy at iteration 14700  is               12.575%\n",
            "The validation accuracy at iteration 14800  is               12.575%\n",
            "The validation accuracy at iteration 14900  is               12.575%\n",
            "The validation accuracy at iteration 15000  is               12.575%\n",
            "The validation accuracy at iteration 15100  is               12.575%\n",
            "The validation accuracy at iteration 15200  is               12.575%\n",
            "The validation accuracy at iteration 15300  is               12.575%\n",
            "The validation accuracy at iteration 15400  is               12.575%\n",
            "The validation accuracy at iteration 15500  is               12.575%\n",
            "The validation accuracy at iteration 15600  is               12.575%\n",
            "The validation accuracy at iteration 15700  is               12.575%\n",
            "The validation accuracy at iteration 15800  is               12.575%\n",
            "The validation accuracy at iteration 15900  is               12.575%\n",
            "The validation accuracy at iteration 16000  is               12.575%\n",
            "The validation accuracy at iteration 16000  is               12.575%\n",
            "The validation accuracy at iteration 100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 1900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 2900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 3900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 4900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 5900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 6900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 7900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 8900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 9900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 10900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 11900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 12900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 13900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 14900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15100  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15200  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15300  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15400  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15500  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15600  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15700  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15800  is               13.325000000000001%\n",
            "The validation accuracy at iteration 15900  is               13.325000000000001%\n",
            "The validation accuracy at iteration 16000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 16000  is               13.325000000000001%\n",
            "The validation accuracy at iteration 100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 1900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 2900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 3900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 4900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 5900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 6900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 7900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 8900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 9900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 10900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 11900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 12900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 13900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 14900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15100  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15200  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15300  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15400  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15500  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15600  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15700  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15800  is               13.225000000000001%\n",
            "The validation accuracy at iteration 15900  is               13.225000000000001%\n",
            "The validation accuracy at iteration 16000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 16000  is               13.225000000000001%\n",
            "The validation accuracy at iteration 100  is               11.0%\n",
            "The validation accuracy at iteration 200  is               11.0%\n",
            "The validation accuracy at iteration 300  is               11.0%\n",
            "The validation accuracy at iteration 400  is               11.0%\n",
            "The validation accuracy at iteration 500  is               11.0%\n",
            "The validation accuracy at iteration 600  is               11.0%\n",
            "The validation accuracy at iteration 700  is               11.0%\n",
            "The validation accuracy at iteration 800  is               11.0%\n",
            "The validation accuracy at iteration 900  is               11.0%\n",
            "The validation accuracy at iteration 1000  is               11.0%\n",
            "The validation accuracy at iteration 1100  is               11.0%\n",
            "The validation accuracy at iteration 1200  is               11.0%\n",
            "The validation accuracy at iteration 1300  is               11.0%\n",
            "The validation accuracy at iteration 1400  is               11.0%\n",
            "The validation accuracy at iteration 1500  is               11.0%\n",
            "The validation accuracy at iteration 1600  is               11.0%\n",
            "The validation accuracy at iteration 1700  is               11.0%\n",
            "The validation accuracy at iteration 1800  is               11.0%\n",
            "The validation accuracy at iteration 1900  is               11.0%\n",
            "The validation accuracy at iteration 2000  is               11.0%\n",
            "The validation accuracy at iteration 2100  is               11.0%\n",
            "The validation accuracy at iteration 2200  is               11.0%\n",
            "The validation accuracy at iteration 2300  is               11.0%\n",
            "The validation accuracy at iteration 2400  is               11.0%\n",
            "The validation accuracy at iteration 2500  is               11.0%\n",
            "The validation accuracy at iteration 2600  is               11.0%\n",
            "The validation accuracy at iteration 2700  is               11.0%\n",
            "The validation accuracy at iteration 2800  is               11.0%\n",
            "The validation accuracy at iteration 2900  is               11.0%\n",
            "The validation accuracy at iteration 3000  is               11.0%\n",
            "The validation accuracy at iteration 3100  is               11.0%\n",
            "The validation accuracy at iteration 3200  is               11.0%\n",
            "The validation accuracy at iteration 3300  is               11.0%\n",
            "The validation accuracy at iteration 3400  is               11.0%\n",
            "The validation accuracy at iteration 3500  is               11.0%\n",
            "The validation accuracy at iteration 3600  is               11.0%\n",
            "The validation accuracy at iteration 3700  is               11.0%\n",
            "The validation accuracy at iteration 3800  is               11.0%\n",
            "The validation accuracy at iteration 3900  is               11.0%\n",
            "The validation accuracy at iteration 4000  is               11.0%\n",
            "The validation accuracy at iteration 4100  is               11.0%\n",
            "The validation accuracy at iteration 4200  is               11.0%\n",
            "The validation accuracy at iteration 4300  is               11.0%\n",
            "The validation accuracy at iteration 4400  is               11.0%\n",
            "The validation accuracy at iteration 4500  is               11.0%\n",
            "The validation accuracy at iteration 4600  is               11.0%\n",
            "The validation accuracy at iteration 4700  is               11.0%\n",
            "The validation accuracy at iteration 4800  is               11.0%\n",
            "The validation accuracy at iteration 4900  is               11.0%\n",
            "The validation accuracy at iteration 5000  is               11.0%\n",
            "The validation accuracy at iteration 5100  is               11.0%\n",
            "The validation accuracy at iteration 5200  is               11.0%\n",
            "The validation accuracy at iteration 5300  is               11.0%\n",
            "The validation accuracy at iteration 5400  is               11.0%\n",
            "The validation accuracy at iteration 5500  is               11.0%\n",
            "The validation accuracy at iteration 5600  is               11.0%\n",
            "The validation accuracy at iteration 5700  is               11.0%\n",
            "The validation accuracy at iteration 5800  is               11.0%\n",
            "The validation accuracy at iteration 5900  is               11.0%\n",
            "The validation accuracy at iteration 6000  is               11.0%\n",
            "The validation accuracy at iteration 6100  is               11.0%\n",
            "The validation accuracy at iteration 6200  is               11.0%\n",
            "The validation accuracy at iteration 6300  is               11.0%\n",
            "The validation accuracy at iteration 6400  is               11.0%\n",
            "The validation accuracy at iteration 6500  is               11.0%\n",
            "The validation accuracy at iteration 6600  is               11.0%\n",
            "The validation accuracy at iteration 6700  is               11.0%\n",
            "The validation accuracy at iteration 6800  is               11.0%\n",
            "The validation accuracy at iteration 6900  is               11.0%\n",
            "The validation accuracy at iteration 7000  is               11.0%\n",
            "The validation accuracy at iteration 7100  is               11.0%\n",
            "The validation accuracy at iteration 7200  is               11.0%\n",
            "The validation accuracy at iteration 7300  is               11.0%\n",
            "The validation accuracy at iteration 7400  is               11.0%\n",
            "The validation accuracy at iteration 7500  is               11.0%\n",
            "The validation accuracy at iteration 7600  is               11.0%\n",
            "The validation accuracy at iteration 7700  is               11.0%\n",
            "The validation accuracy at iteration 7800  is               11.0%\n",
            "The validation accuracy at iteration 7900  is               11.0%\n",
            "The validation accuracy at iteration 8000  is               11.0%\n",
            "The validation accuracy at iteration 8100  is               11.0%\n",
            "The validation accuracy at iteration 8200  is               11.0%\n",
            "The validation accuracy at iteration 8300  is               11.0%\n",
            "The validation accuracy at iteration 8400  is               11.0%\n",
            "The validation accuracy at iteration 8500  is               11.0%\n",
            "The validation accuracy at iteration 8600  is               11.0%\n",
            "The validation accuracy at iteration 8700  is               11.0%\n",
            "The validation accuracy at iteration 8800  is               11.0%\n",
            "The validation accuracy at iteration 8900  is               11.0%\n",
            "The validation accuracy at iteration 9000  is               11.0%\n",
            "The validation accuracy at iteration 9100  is               11.0%\n",
            "The validation accuracy at iteration 9200  is               11.0%\n",
            "The validation accuracy at iteration 9300  is               11.0%\n",
            "The validation accuracy at iteration 9400  is               11.0%\n",
            "The validation accuracy at iteration 9500  is               11.0%\n",
            "The validation accuracy at iteration 9600  is               11.0%\n",
            "The validation accuracy at iteration 9700  is               11.0%\n",
            "The validation accuracy at iteration 9800  is               11.0%\n",
            "The validation accuracy at iteration 9900  is               11.0%\n",
            "The validation accuracy at iteration 10000  is               11.0%\n",
            "The validation accuracy at iteration 10100  is               11.0%\n",
            "The validation accuracy at iteration 10200  is               11.0%\n",
            "The validation accuracy at iteration 10300  is               11.0%\n",
            "The validation accuracy at iteration 10400  is               11.0%\n",
            "The validation accuracy at iteration 10500  is               11.0%\n",
            "The validation accuracy at iteration 10600  is               11.0%\n",
            "The validation accuracy at iteration 10700  is               11.0%\n",
            "The validation accuracy at iteration 10800  is               11.0%\n",
            "The validation accuracy at iteration 10900  is               11.0%\n",
            "The validation accuracy at iteration 11000  is               11.0%\n",
            "The validation accuracy at iteration 11100  is               11.0%\n",
            "The validation accuracy at iteration 11200  is               11.0%\n",
            "The validation accuracy at iteration 11300  is               11.0%\n",
            "The validation accuracy at iteration 11400  is               11.0%\n",
            "The validation accuracy at iteration 11500  is               11.0%\n",
            "The validation accuracy at iteration 11600  is               11.0%\n",
            "The validation accuracy at iteration 11700  is               11.0%\n",
            "The validation accuracy at iteration 11800  is               11.0%\n",
            "The validation accuracy at iteration 11900  is               11.0%\n",
            "The validation accuracy at iteration 12000  is               11.0%\n",
            "The validation accuracy at iteration 12100  is               11.0%\n",
            "The validation accuracy at iteration 12200  is               11.0%\n",
            "The validation accuracy at iteration 12300  is               11.0%\n",
            "The validation accuracy at iteration 12400  is               11.0%\n",
            "The validation accuracy at iteration 12500  is               11.0%\n",
            "The validation accuracy at iteration 12600  is               11.0%\n",
            "The validation accuracy at iteration 12700  is               11.0%\n",
            "The validation accuracy at iteration 12800  is               11.0%\n",
            "The validation accuracy at iteration 12900  is               11.0%\n",
            "The validation accuracy at iteration 13000  is               11.0%\n",
            "The validation accuracy at iteration 13100  is               11.0%\n",
            "The validation accuracy at iteration 13200  is               11.0%\n",
            "The validation accuracy at iteration 13300  is               11.0%\n",
            "The validation accuracy at iteration 13400  is               11.0%\n",
            "The validation accuracy at iteration 13500  is               11.0%\n",
            "The validation accuracy at iteration 13600  is               11.0%\n",
            "The validation accuracy at iteration 13700  is               11.0%\n",
            "The validation accuracy at iteration 13800  is               11.0%\n",
            "The validation accuracy at iteration 13900  is               11.0%\n",
            "The validation accuracy at iteration 14000  is               11.0%\n",
            "The validation accuracy at iteration 14100  is               11.0%\n",
            "The validation accuracy at iteration 14200  is               11.0%\n",
            "The validation accuracy at iteration 14300  is               11.0%\n",
            "The validation accuracy at iteration 14400  is               11.0%\n",
            "The validation accuracy at iteration 14500  is               11.0%\n",
            "The validation accuracy at iteration 14600  is               11.0%\n",
            "The validation accuracy at iteration 14700  is               11.0%\n",
            "The validation accuracy at iteration 14800  is               11.0%\n",
            "The validation accuracy at iteration 14900  is               11.0%\n",
            "The validation accuracy at iteration 15000  is               11.0%\n",
            "The validation accuracy at iteration 15100  is               11.0%\n",
            "The validation accuracy at iteration 15200  is               11.0%\n",
            "The validation accuracy at iteration 15300  is               11.0%\n",
            "The validation accuracy at iteration 15400  is               11.0%\n",
            "The validation accuracy at iteration 15500  is               11.0%\n",
            "The validation accuracy at iteration 15600  is               11.0%\n",
            "The validation accuracy at iteration 15700  is               11.0%\n",
            "The validation accuracy at iteration 15800  is               11.0%\n",
            "The validation accuracy at iteration 15900  is               11.0%\n",
            "The validation accuracy at iteration 16000  is               11.0%\n",
            "The validation accuracy at iteration 16000  is               11.0%\n",
            "The validation accuracy at iteration 100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 1900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 2900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 3900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 4900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 5900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 6900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 7900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 8900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 9900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 10900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 11900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 12900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 13900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 14900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15100  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15200  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15300  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15400  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15500  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15600  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15700  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15800  is               10.299999999999999%\n",
            "The validation accuracy at iteration 15900  is               10.299999999999999%\n",
            "The validation accuracy at iteration 16000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 16000  is               10.299999999999999%\n",
            "The validation accuracy at iteration 100  is               16.475%\n",
            "The validation accuracy at iteration 200  is               16.475%\n",
            "The validation accuracy at iteration 300  is               16.475%\n",
            "The validation accuracy at iteration 400  is               16.475%\n",
            "The validation accuracy at iteration 500  is               16.475%\n",
            "The validation accuracy at iteration 600  is               16.475%\n",
            "The validation accuracy at iteration 700  is               16.475%\n",
            "The validation accuracy at iteration 800  is               16.475%\n",
            "The validation accuracy at iteration 900  is               16.475%\n",
            "The validation accuracy at iteration 1000  is               16.475%\n",
            "The validation accuracy at iteration 1100  is               16.475%\n",
            "The validation accuracy at iteration 1200  is               16.475%\n",
            "The validation accuracy at iteration 1300  is               16.475%\n",
            "The validation accuracy at iteration 1400  is               16.475%\n",
            "The validation accuracy at iteration 1500  is               16.475%\n",
            "The validation accuracy at iteration 1600  is               16.475%\n",
            "The validation accuracy at iteration 1700  is               16.475%\n",
            "The validation accuracy at iteration 1800  is               16.475%\n",
            "The validation accuracy at iteration 1900  is               16.475%\n",
            "The validation accuracy at iteration 2000  is               16.475%\n",
            "The validation accuracy at iteration 2100  is               16.475%\n",
            "The validation accuracy at iteration 2200  is               16.475%\n",
            "The validation accuracy at iteration 2300  is               16.475%\n",
            "The validation accuracy at iteration 2400  is               16.475%\n",
            "The validation accuracy at iteration 2500  is               16.475%\n",
            "The validation accuracy at iteration 2600  is               16.475%\n",
            "The validation accuracy at iteration 2700  is               16.475%\n",
            "The validation accuracy at iteration 2800  is               16.475%\n",
            "The validation accuracy at iteration 2900  is               16.475%\n",
            "The validation accuracy at iteration 3000  is               16.475%\n",
            "The validation accuracy at iteration 3100  is               16.475%\n",
            "The validation accuracy at iteration 3200  is               16.475%\n",
            "The validation accuracy at iteration 3300  is               16.475%\n",
            "The validation accuracy at iteration 3400  is               16.475%\n",
            "The validation accuracy at iteration 3500  is               16.475%\n",
            "The validation accuracy at iteration 3600  is               16.475%\n",
            "The validation accuracy at iteration 3700  is               16.475%\n",
            "The validation accuracy at iteration 3800  is               16.475%\n",
            "The validation accuracy at iteration 3900  is               16.475%\n",
            "The validation accuracy at iteration 4000  is               16.475%\n",
            "The validation accuracy at iteration 4100  is               16.475%\n",
            "The validation accuracy at iteration 4200  is               16.475%\n",
            "The validation accuracy at iteration 4300  is               16.475%\n",
            "The validation accuracy at iteration 4400  is               16.475%\n",
            "The validation accuracy at iteration 4500  is               16.475%\n",
            "The validation accuracy at iteration 4600  is               16.475%\n",
            "The validation accuracy at iteration 4700  is               16.475%\n",
            "The validation accuracy at iteration 4800  is               16.475%\n",
            "The validation accuracy at iteration 4900  is               16.475%\n",
            "The validation accuracy at iteration 5000  is               16.475%\n",
            "The validation accuracy at iteration 5100  is               16.475%\n",
            "The validation accuracy at iteration 5200  is               16.475%\n",
            "The validation accuracy at iteration 5300  is               16.475%\n",
            "The validation accuracy at iteration 5400  is               16.475%\n",
            "The validation accuracy at iteration 5500  is               16.475%\n",
            "The validation accuracy at iteration 5600  is               16.475%\n",
            "The validation accuracy at iteration 5700  is               16.475%\n",
            "The validation accuracy at iteration 5800  is               16.475%\n",
            "The validation accuracy at iteration 5900  is               16.475%\n",
            "The validation accuracy at iteration 6000  is               16.475%\n",
            "The validation accuracy at iteration 6100  is               16.475%\n",
            "The validation accuracy at iteration 6200  is               16.475%\n",
            "The validation accuracy at iteration 6300  is               16.475%\n",
            "The validation accuracy at iteration 6400  is               16.475%\n",
            "The validation accuracy at iteration 6500  is               16.475%\n",
            "The validation accuracy at iteration 6600  is               16.475%\n",
            "The validation accuracy at iteration 6700  is               16.475%\n",
            "The validation accuracy at iteration 6800  is               16.475%\n",
            "The validation accuracy at iteration 6900  is               16.475%\n",
            "The validation accuracy at iteration 7000  is               16.475%\n",
            "The validation accuracy at iteration 7100  is               16.475%\n",
            "The validation accuracy at iteration 7200  is               16.475%\n",
            "The validation accuracy at iteration 7300  is               16.475%\n",
            "The validation accuracy at iteration 7400  is               16.475%\n",
            "The validation accuracy at iteration 7500  is               16.475%\n",
            "The validation accuracy at iteration 7600  is               16.475%\n",
            "The validation accuracy at iteration 7700  is               16.475%\n",
            "The validation accuracy at iteration 7800  is               16.475%\n",
            "The validation accuracy at iteration 7900  is               16.475%\n",
            "The validation accuracy at iteration 8000  is               16.475%\n",
            "The validation accuracy at iteration 8100  is               16.475%\n",
            "The validation accuracy at iteration 8200  is               16.475%\n",
            "The validation accuracy at iteration 8300  is               16.475%\n",
            "The validation accuracy at iteration 8400  is               16.475%\n",
            "The validation accuracy at iteration 8500  is               16.475%\n",
            "The validation accuracy at iteration 8600  is               16.475%\n",
            "The validation accuracy at iteration 8700  is               16.475%\n",
            "The validation accuracy at iteration 8800  is               16.475%\n",
            "The validation accuracy at iteration 8900  is               16.475%\n",
            "The validation accuracy at iteration 9000  is               16.475%\n",
            "The validation accuracy at iteration 9100  is               16.475%\n",
            "The validation accuracy at iteration 9200  is               16.475%\n",
            "The validation accuracy at iteration 9300  is               16.475%\n",
            "The validation accuracy at iteration 9400  is               16.475%\n",
            "The validation accuracy at iteration 9500  is               16.475%\n",
            "The validation accuracy at iteration 9600  is               16.475%\n",
            "The validation accuracy at iteration 9700  is               16.475%\n",
            "The validation accuracy at iteration 9800  is               16.475%\n",
            "The validation accuracy at iteration 9900  is               16.475%\n",
            "The validation accuracy at iteration 10000  is               16.475%\n",
            "The validation accuracy at iteration 10100  is               16.475%\n",
            "The validation accuracy at iteration 10200  is               16.475%\n",
            "The validation accuracy at iteration 10300  is               16.475%\n",
            "The validation accuracy at iteration 10400  is               16.475%\n",
            "The validation accuracy at iteration 10500  is               16.475%\n",
            "The validation accuracy at iteration 10600  is               16.475%\n",
            "The validation accuracy at iteration 10700  is               16.475%\n",
            "The validation accuracy at iteration 10800  is               16.475%\n",
            "The validation accuracy at iteration 10900  is               16.475%\n",
            "The validation accuracy at iteration 11000  is               16.475%\n",
            "The validation accuracy at iteration 11100  is               16.475%\n",
            "The validation accuracy at iteration 11200  is               16.475%\n",
            "The validation accuracy at iteration 11300  is               16.475%\n",
            "The validation accuracy at iteration 11400  is               16.475%\n",
            "The validation accuracy at iteration 11500  is               16.475%\n",
            "The validation accuracy at iteration 11600  is               16.475%\n",
            "The validation accuracy at iteration 11700  is               16.475%\n",
            "The validation accuracy at iteration 11800  is               16.475%\n",
            "The validation accuracy at iteration 11900  is               16.475%\n",
            "The validation accuracy at iteration 12000  is               16.475%\n",
            "The validation accuracy at iteration 12100  is               16.475%\n",
            "The validation accuracy at iteration 12200  is               16.475%\n",
            "The validation accuracy at iteration 12300  is               16.475%\n",
            "The validation accuracy at iteration 12400  is               16.475%\n",
            "The validation accuracy at iteration 12500  is               16.475%\n",
            "The validation accuracy at iteration 12600  is               16.475%\n",
            "The validation accuracy at iteration 12700  is               16.475%\n",
            "The validation accuracy at iteration 12800  is               16.475%\n",
            "The validation accuracy at iteration 12900  is               16.475%\n",
            "The validation accuracy at iteration 13000  is               16.475%\n",
            "The validation accuracy at iteration 13100  is               16.475%\n",
            "The validation accuracy at iteration 13200  is               16.475%\n",
            "The validation accuracy at iteration 13300  is               16.475%\n",
            "The validation accuracy at iteration 13400  is               16.475%\n",
            "The validation accuracy at iteration 13500  is               16.475%\n",
            "The validation accuracy at iteration 13600  is               16.475%\n",
            "The validation accuracy at iteration 13700  is               16.475%\n",
            "The validation accuracy at iteration 13800  is               16.475%\n",
            "The validation accuracy at iteration 13900  is               16.475%\n",
            "The validation accuracy at iteration 14000  is               16.475%\n",
            "The validation accuracy at iteration 14100  is               16.475%\n",
            "The validation accuracy at iteration 14200  is               16.475%\n",
            "The validation accuracy at iteration 14300  is               16.475%\n",
            "The validation accuracy at iteration 14400  is               16.475%\n",
            "The validation accuracy at iteration 14500  is               16.475%\n",
            "The validation accuracy at iteration 14600  is               16.475%\n",
            "The validation accuracy at iteration 14700  is               16.475%\n",
            "The validation accuracy at iteration 14800  is               16.475%\n",
            "The validation accuracy at iteration 14900  is               16.475%\n",
            "The validation accuracy at iteration 15000  is               16.475%\n",
            "The validation accuracy at iteration 15100  is               16.475%\n",
            "The validation accuracy at iteration 15200  is               16.475%\n",
            "The validation accuracy at iteration 15300  is               16.475%\n",
            "The validation accuracy at iteration 15400  is               16.475%\n",
            "The validation accuracy at iteration 15500  is               16.475%\n",
            "The validation accuracy at iteration 15600  is               16.475%\n",
            "The validation accuracy at iteration 15700  is               16.475%\n",
            "The validation accuracy at iteration 15800  is               16.475%\n",
            "The validation accuracy at iteration 15900  is               16.475%\n",
            "The validation accuracy at iteration 16000  is               16.475%\n",
            "The validation accuracy at iteration 16000  is               16.475%\n",
            "The validation accuracy at iteration 100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 1900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 2900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 3900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 4900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 5900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 6900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 7900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 8900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 9900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 10900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 11900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 12900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 13900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 14900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15100  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15200  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15300  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15400  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15500  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15600  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15700  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15800  is               7.449999999999999%\n",
            "The validation accuracy at iteration 15900  is               7.449999999999999%\n",
            "The validation accuracy at iteration 16000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 16000  is               7.449999999999999%\n",
            "The validation accuracy at iteration 100  is               4.6%\n",
            "The validation accuracy at iteration 200  is               4.6%\n",
            "The validation accuracy at iteration 300  is               4.6%\n",
            "The validation accuracy at iteration 400  is               4.6%\n",
            "The validation accuracy at iteration 500  is               4.6%\n",
            "The validation accuracy at iteration 600  is               4.6%\n",
            "The validation accuracy at iteration 700  is               4.6%\n",
            "The validation accuracy at iteration 800  is               4.6%\n",
            "The validation accuracy at iteration 900  is               4.6%\n",
            "The validation accuracy at iteration 1000  is               4.6%\n",
            "The validation accuracy at iteration 1100  is               4.6%\n",
            "The validation accuracy at iteration 1200  is               4.6%\n",
            "The validation accuracy at iteration 1300  is               4.6%\n",
            "The validation accuracy at iteration 1400  is               4.6%\n",
            "The validation accuracy at iteration 1500  is               4.6%\n",
            "The validation accuracy at iteration 1600  is               4.6%\n",
            "The validation accuracy at iteration 1700  is               4.6%\n",
            "The validation accuracy at iteration 1800  is               4.6%\n",
            "The validation accuracy at iteration 1900  is               4.6%\n",
            "The validation accuracy at iteration 2000  is               4.6%\n",
            "The validation accuracy at iteration 2100  is               4.6%\n",
            "The validation accuracy at iteration 2200  is               4.6%\n",
            "The validation accuracy at iteration 2300  is               4.6%\n",
            "The validation accuracy at iteration 2400  is               4.6%\n",
            "The validation accuracy at iteration 2500  is               4.6%\n",
            "The validation accuracy at iteration 2600  is               4.6%\n",
            "The validation accuracy at iteration 2700  is               4.6%\n",
            "The validation accuracy at iteration 2800  is               4.6%\n",
            "The validation accuracy at iteration 2900  is               4.6%\n",
            "The validation accuracy at iteration 3000  is               4.6%\n",
            "The validation accuracy at iteration 3100  is               4.6%\n",
            "The validation accuracy at iteration 3200  is               4.6%\n",
            "The validation accuracy at iteration 3300  is               4.6%\n",
            "The validation accuracy at iteration 3400  is               4.6%\n",
            "The validation accuracy at iteration 3500  is               4.6%\n",
            "The validation accuracy at iteration 3600  is               4.6%\n",
            "The validation accuracy at iteration 3700  is               4.6%\n",
            "The validation accuracy at iteration 3800  is               4.6%\n",
            "The validation accuracy at iteration 3900  is               4.6%\n",
            "The validation accuracy at iteration 4000  is               4.6%\n",
            "The validation accuracy at iteration 4100  is               4.6%\n",
            "The validation accuracy at iteration 4200  is               4.6%\n",
            "The validation accuracy at iteration 4300  is               4.6%\n",
            "The validation accuracy at iteration 4400  is               4.6%\n",
            "The validation accuracy at iteration 4500  is               4.6%\n",
            "The validation accuracy at iteration 4600  is               4.6%\n",
            "The validation accuracy at iteration 4700  is               4.6%\n",
            "The validation accuracy at iteration 4800  is               4.6%\n",
            "The validation accuracy at iteration 4900  is               4.6%\n",
            "The validation accuracy at iteration 5000  is               4.6%\n",
            "The validation accuracy at iteration 5100  is               4.6%\n",
            "The validation accuracy at iteration 5200  is               4.6%\n",
            "The validation accuracy at iteration 5300  is               4.6%\n",
            "The validation accuracy at iteration 5400  is               4.6%\n",
            "The validation accuracy at iteration 5500  is               4.6%\n",
            "The validation accuracy at iteration 5600  is               4.6%\n",
            "The validation accuracy at iteration 5700  is               4.6%\n",
            "The validation accuracy at iteration 5800  is               4.6%\n",
            "The validation accuracy at iteration 5900  is               4.6%\n",
            "The validation accuracy at iteration 6000  is               4.6%\n",
            "The validation accuracy at iteration 6100  is               4.6%\n",
            "The validation accuracy at iteration 6200  is               4.6%\n",
            "The validation accuracy at iteration 6300  is               4.6%\n",
            "The validation accuracy at iteration 6400  is               4.6%\n",
            "The validation accuracy at iteration 6500  is               4.6%\n",
            "The validation accuracy at iteration 6600  is               4.6%\n",
            "The validation accuracy at iteration 6700  is               4.6%\n",
            "The validation accuracy at iteration 6800  is               4.6%\n",
            "The validation accuracy at iteration 6900  is               4.6%\n",
            "The validation accuracy at iteration 7000  is               4.6%\n",
            "The validation accuracy at iteration 7100  is               4.6%\n",
            "The validation accuracy at iteration 7200  is               4.6%\n",
            "The validation accuracy at iteration 7300  is               4.6%\n",
            "The validation accuracy at iteration 7400  is               4.6%\n",
            "The validation accuracy at iteration 7500  is               4.6%\n",
            "The validation accuracy at iteration 7600  is               4.6%\n",
            "The validation accuracy at iteration 7700  is               4.6%\n",
            "The validation accuracy at iteration 7800  is               4.6%\n",
            "The validation accuracy at iteration 7900  is               4.6%\n",
            "The validation accuracy at iteration 8000  is               4.6%\n",
            "The validation accuracy at iteration 8100  is               4.6%\n",
            "The validation accuracy at iteration 8200  is               4.6%\n",
            "The validation accuracy at iteration 8300  is               4.6%\n",
            "The validation accuracy at iteration 8400  is               4.6%\n",
            "The validation accuracy at iteration 8500  is               4.6%\n",
            "The validation accuracy at iteration 8600  is               4.6%\n",
            "The validation accuracy at iteration 8700  is               4.6%\n",
            "The validation accuracy at iteration 8800  is               4.6%\n",
            "The validation accuracy at iteration 8900  is               4.6%\n",
            "The validation accuracy at iteration 9000  is               4.6%\n",
            "The validation accuracy at iteration 9100  is               4.6%\n",
            "The validation accuracy at iteration 9200  is               4.6%\n",
            "The validation accuracy at iteration 9300  is               4.6%\n",
            "The validation accuracy at iteration 9400  is               4.6%\n",
            "The validation accuracy at iteration 9500  is               4.6%\n",
            "The validation accuracy at iteration 9600  is               4.6%\n",
            "The validation accuracy at iteration 9700  is               4.6%\n",
            "The validation accuracy at iteration 9800  is               4.6%\n",
            "The validation accuracy at iteration 9900  is               4.6%\n",
            "The validation accuracy at iteration 10000  is               4.6%\n",
            "The validation accuracy at iteration 10100  is               4.6%\n",
            "The validation accuracy at iteration 10200  is               4.6%\n",
            "The validation accuracy at iteration 10300  is               4.6%\n",
            "The validation accuracy at iteration 10400  is               4.6%\n",
            "The validation accuracy at iteration 10500  is               4.6%\n",
            "The validation accuracy at iteration 10600  is               4.6%\n",
            "The validation accuracy at iteration 10700  is               4.6%\n",
            "The validation accuracy at iteration 10800  is               4.6%\n",
            "The validation accuracy at iteration 10900  is               4.6%\n",
            "The validation accuracy at iteration 11000  is               4.6%\n",
            "The validation accuracy at iteration 11100  is               4.6%\n",
            "The validation accuracy at iteration 11200  is               4.6%\n",
            "The validation accuracy at iteration 11300  is               4.6%\n",
            "The validation accuracy at iteration 11400  is               4.6%\n",
            "The validation accuracy at iteration 11500  is               4.6%\n",
            "The validation accuracy at iteration 11600  is               4.6%\n",
            "The validation accuracy at iteration 11700  is               4.6%\n",
            "The validation accuracy at iteration 11800  is               4.6%\n",
            "The validation accuracy at iteration 11900  is               4.6%\n",
            "The validation accuracy at iteration 12000  is               4.6%\n",
            "The validation accuracy at iteration 12100  is               4.6%\n",
            "The validation accuracy at iteration 12200  is               4.6%\n",
            "The validation accuracy at iteration 12300  is               4.6%\n",
            "The validation accuracy at iteration 12400  is               4.6%\n",
            "The validation accuracy at iteration 12500  is               4.6%\n",
            "The validation accuracy at iteration 12600  is               4.6%\n",
            "The validation accuracy at iteration 12700  is               4.6%\n",
            "The validation accuracy at iteration 12800  is               4.6%\n",
            "The validation accuracy at iteration 12900  is               4.6%\n",
            "The validation accuracy at iteration 13000  is               4.6%\n",
            "The validation accuracy at iteration 13100  is               4.6%\n",
            "The validation accuracy at iteration 13200  is               4.6%\n",
            "The validation accuracy at iteration 13300  is               4.6%\n",
            "The validation accuracy at iteration 13400  is               4.6%\n",
            "The validation accuracy at iteration 13500  is               4.6%\n",
            "The validation accuracy at iteration 13600  is               4.6%\n",
            "The validation accuracy at iteration 13700  is               4.6%\n",
            "The validation accuracy at iteration 13800  is               4.6%\n",
            "The validation accuracy at iteration 13900  is               4.6%\n",
            "The validation accuracy at iteration 14000  is               4.6%\n",
            "The validation accuracy at iteration 14100  is               4.6%\n",
            "The validation accuracy at iteration 14200  is               4.6%\n",
            "The validation accuracy at iteration 14300  is               4.6%\n",
            "The validation accuracy at iteration 14400  is               4.6%\n",
            "The validation accuracy at iteration 14500  is               4.6%\n",
            "The validation accuracy at iteration 14600  is               4.6%\n",
            "The validation accuracy at iteration 14700  is               4.6%\n",
            "The validation accuracy at iteration 14800  is               4.6%\n",
            "The validation accuracy at iteration 14900  is               4.6%\n",
            "The validation accuracy at iteration 15000  is               4.6%\n",
            "The validation accuracy at iteration 15100  is               4.6%\n",
            "The validation accuracy at iteration 15200  is               4.6%\n",
            "The validation accuracy at iteration 15300  is               4.6%\n",
            "The validation accuracy at iteration 15400  is               4.6%\n",
            "The validation accuracy at iteration 15500  is               4.6%\n",
            "The validation accuracy at iteration 15600  is               4.6%\n",
            "The validation accuracy at iteration 15700  is               4.6%\n",
            "The validation accuracy at iteration 15800  is               4.6%\n",
            "The validation accuracy at iteration 15900  is               4.6%\n",
            "The validation accuracy at iteration 16000  is               4.6%\n",
            "The validation accuracy at iteration 16000  is               4.6%\n",
            "Top 1 Model: Learning Rate = 1e-08, Validation Accuracy = 16.48%\n",
            "Top 2 Model: Learning Rate = 0.0001, Validation Accuracy = 13.33%\n",
            "Top 3 Model: Learning Rate = 1e-05, Validation Accuracy = 13.23%\n",
            "Top 4 Model: Learning Rate = 0.001, Validation Accuracy = 12.57%\n",
            "Top 5 Model: Learning Rate = 1e-06, Validation Accuracy = 11.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the next cell to visualize the weights corresponding to each sample in the *best* performing softmax models.\n",
        "You should have ten 28x28 images.\n",
        "\n",
        "You can add additional cells below.\n",
        "\n",
        "Depending on your learning rate and weights, it might not look so great. If all the images look the same but you have good accuracy, try subtracting the average of weights from weights of each class."
      ],
      "metadata": {
        "id": "s8j9KoxfXgY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "top_model, _, _ = best_models[0]\n",
        "min_weight = np.min(weights)\n",
        "max_weight = np.max(weights)\n",
        "rescaled_weights = (weights - min_weight) / (max_weight - min_weight) * 255\n",
        "fig, axs = plt.subplots(1, 10, figsize=(20, 2))\n",
        "for i in range(10):\n",
        "    weight_image = rescaled_weights[:, i].reshape(28, 28)\n",
        "    axs[i].imshow(weight_image, cmap='gray')\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(f'Class {i}')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0SEDP9m-EZNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "c4be9cf4-e6a7-4b14-d46c-49e6db4db746"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top 5 performing softmax models on the test set and print the results."
      ],
      "metadata": {
        "id": "4GdpbgYg5D8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = get_mnist_test_data()\n",
        "x_test = (x_test - x_mean) / x_std\n",
        "def test_model(model, x_test, y_test):\n",
        "    predictions = model.predict(x_test)\n",
        "    accuracy = np.mean(predictions == y_test.astype(int))\n",
        "    return accuracy\n",
        "\n",
        "test_accuracies = []\n",
        "\n",
        "for model, _, _ in best_models:\n",
        "    accuracy = test_model(model, x_test, y_test)\n",
        "    test_accuracies.append(accuracy)\n",
        "\n",
        "for idx, accuracy in enumerate(test_accuracies, start=1):\n",
        "    print(f\"Top {idx} Model Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oxuJHeU45EVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb7ef1d-7eac-4616-9113-961a383408b6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 Model Test Accuracy: 17.02%\n",
            "Top 2 Model Test Accuracy: 12.45%\n",
            "Top 3 Model Test Accuracy: 12.40%\n",
            "Top 4 Model Test Accuracy: 12.45%\n",
            "Top 5 Model Test Accuracy: 10.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Deeper Neural Networks (Very Slightly)"
      ],
      "metadata": {
        "id": "A7mX-suZStG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up until now, we have been working with linear classification models.\n",
        "Linear classification models are very adept at modelling data that have nice linear boundaries.\n",
        "In practice, real world data is rarely linear.\n",
        "Multilayer, fully-connected neural networks with non-linear activation functions on the other hand can model non-linear data-label relationships.\n",
        "Such models are a powerful extension to linear models and are the building blocks of modern deep learning.\n",
        "\n",
        "In this section,\n",
        "you will be implementing a two-layer, fully-connected neural network.\n",
        "You will also implement your own version of the rectified linear unit fuction (commonly reffered to as ReLU),\n",
        "a non-linear activation function."
      ],
      "metadata": {
        "id": "j60wKxwhXu2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 ReLU Function\n",
        "\n",
        "The ReLU function is given by:\n",
        "\n",
        "$$\n",
        "f(x) = \\max(0, x)\n",
        "$$"
      ],
      "metadata": {
        "id": "gP_YgE1JWj1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the following cell to complete the definition of the `ReLU_forward` function."
      ],
      "metadata": {
        "id": "SF20M-YOWSdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_forward(x):\n",
        "    \"\"\"\n",
        "    Computes the forward pass for a ReLU actiivation.\n",
        "\n",
        "    The input x has shape (N, D) and contains a minibatch of N\n",
        "    examples, where each example x[i] has shape (D). We will\n",
        "    transform it to an output vector of dimension M.\n",
        "\n",
        "    Inputs:\n",
        "    - x: A numpy array containing input data, of shape (N, D)\n",
        "\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - out: output, of shape (N, D)\n",
        "    - cache: (x)\n",
        "    \"\"\"\n",
        "    out = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU forward pass. Store the result in\n",
        "    # out. You will need to reshape the input into rows.\n",
        "\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    cache = (x,)\n",
        "    return out, cache"
      ],
      "metadata": {
        "id": "tQ-CcTqJStgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ReLU derivative is given by:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial f(x)}{\\partial x} = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "      0 & x \\leq 0 \\\\\n",
        "      1 & x > 0 \\\\\n",
        "\\end{array}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Where $f(x)$ is the ReLU function."
      ],
      "metadata": {
        "id": "g3LU7V4Ib4xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the following cell to complete the definition of the `ReLU_backward(d_upstream, cache)` function."
      ],
      "metadata": {
        "id": "ScME_zhFWXsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU_backward(d_upstream, cache):\n",
        "    \"\"\"\n",
        "    Computes the backward pass for an linear layer.\n",
        "\n",
        "    Inputs:\n",
        "    - d_upstream: Upstream derivative, of shape (N, D)\n",
        "    - cache: Tuple of:\n",
        "      - x: Input data, of shape (N, D)\n",
        "\n",
        "    Returns a tuple of:\n",
        "    - dx: Gradient with respect to x, of shape (N, D)\n",
        "    \"\"\"\n",
        "    x,  = cache\n",
        "    dx = None\n",
        "\n",
        "    # PUT YOUR CODE BELOW: Implement the ReLU backward pass.\n",
        "\n",
        "    # The lines below do not need to be changed.\n",
        "\n",
        "    return (dx, )"
      ],
      "metadata": {
        "id": "fTn6t0FaVBSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Two-layer Neural Network\n",
        "\n",
        "We will now implement the model for the two-layer NN.\n",
        "\n",
        "&#9658; Implement the definition of the two-layer neural network below.\n",
        "\n",
        "Similar to the `LinearClassifier` class, you should write the `__init__`, `forward`, `backward`, and `predict` methods. We will be using the cross-entropy loss for this network.\n",
        "\n",
        "Complete the following:\n",
        "- The `__init__()` method initializes the class. You must generate two random weight matrices. We will be using the bias trick, so the bias should concatenated to the weight matrix. They are initialized differently.\n",
        "\n",
        "- The `forward()` method generates the scores for given an input sample, by applying a `linear_forward()` and `ReLU_forward()` with appropriate inputs. Make sure to store and return the cache for the intermediate steps.\n",
        "\n",
        "- The `backward()` method returns the gradients with respect to the inputs and weights, using the `linear_backward()` and `ReLU_backward()`. Make sure the keys for the returned dictionary `weights_gradient` matches the keys in the `self.params` dictionary.\n",
        "\n",
        "- The `predict()` method returns the labels predicted from the scores returned using the `self.forward()` method.\n"
      ],
      "metadata": {
        "id": "jYDMTehxYP75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet(object):\n",
        "    \"\"\"\n",
        "    A two-layer fully-connected neural network with ReLU nonlinearity and\n",
        "    softmax loss that uses a modular layer design. We assume an input dimension\n",
        "    of D, a hidden dimension of H, and perform classification over C classes.\n",
        "\n",
        "    The architecure should be transform - relu - transform - softmax.\n",
        "\n",
        "    Note that this class does not implement gradient descent; instead, it\n",
        "    will interact with a separate Solver object that is responsible for running\n",
        "    optimization.\n",
        "\n",
        "    The learnable parameters of the model are stored in the dictionary\n",
        "    self.params that maps parameter names to numpy arrays.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim=100,\n",
        "                 num_classes=10,\n",
        "                 weight_scale=1e-3):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "\n",
        "        self.params = {}\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Initialize the weights of the two-layer net. Weights should be\n",
        "        # initialized from a Gaussian centered at 0.0 with standard deviation\n",
        "        # equal to weight_scale, and biases should be initialized to zero.\n",
        "        # All weights should be stored in the dictionary self.params, with first\n",
        "        # layer weights and using the keys 'W1' and second layer weights and using\n",
        "        # the keys 'W2'. Make sure to concatenate the weights and biases to make a\n",
        "        # a single matrix for the bias trick!\n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Implement the forward pass of the neural network and return the scores\n",
        "\n",
        "        Inputs:\n",
        "        - x: A numpy array containing input data, of shape (N, self.input_dim)\n",
        "\n",
        "\n",
        "        Returns a tuple of:\n",
        "        - out: output, of shape (N, D)\n",
        "        - Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1)\n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "        \"\"\"\n",
        "        out = None\n",
        "        N, feature_dim = x.shape\n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = None, None, None\n",
        "\n",
        "        if (feature_dim != self.input_dim):\n",
        "            raise Exception(f\"The input feature dimension of {feature_dim} does \\\n",
        "                            not match the expected feature dimension of \\\n",
        "                            {self.input_dim} \")\n",
        "\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a forward pass of the two-layer net.\n",
        "        # The architecture is transform - relu - transform\n",
        "        # Make to store the appropriate cache in the appropriate variables\n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return out, (cache_lin_1, cache_relu_1, cache_lin_2)\n",
        "\n",
        "\n",
        "    def backward(self, dout, cache):\n",
        "        \"\"\"\n",
        "        Implement the backward pass of the neural network and return the\n",
        "        gradients w.r.t the input, and the weights\n",
        "\n",
        "        Inputs:\n",
        "        - dout: Upstream derivative, of shape (N, C)\n",
        "        - cache: Tuple of tuples:\n",
        "          - cache_lin_1: A tuple (x, w1)\n",
        "            - x: data, of shape (N, self.input_dim)\n",
        "            - w1: Weight of linear layer 1 of shape (self.input_dim+1, self.hidden_dim)\n",
        "          - cache_relu_1: A tuple (h, )\n",
        "            - h : data, of shape (N, self.hidden_dim)\n",
        "          - cache_lin_2:  A tuple (h, w2)\n",
        "            - h: data, of shape (N, self.hidden_dim)\n",
        "            - w2: weight of linear 2 of shape (self.hidden_dim+1, C)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - dx: A numpy array of the gradient with respect to x, of shape (N, D)\n",
        "          - weight_gradients: A dictionary of numpy arrays containing the\n",
        "              gradients with respect to the weights.\n",
        "        \"\"\"\n",
        "\n",
        "        weight_gradients = {}\n",
        "        dx = None\n",
        "\n",
        "        N, classes = dout.shape\n",
        "\n",
        "        cache_lin_1, cache_relu_1, cache_lin_2 = cache\n",
        "\n",
        "        if (classes != self.num_classes):\n",
        "            raise Exception(f\"The output class dimension of {classes} does \\\n",
        "                            not match the expected number of classes \\\n",
        "                            {self.num_classes} \")\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Perform a backward pass of the two-layer net.\n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return (dx, weight_gradients)\n",
        "\n",
        "    def predict(self, x):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the predictions from the forward pass of the neural network and\n",
        "        returns it.\n",
        "\n",
        "        Inputs:\n",
        "        - x: Input data, of shape (N, self.input_dim)\n",
        "\n",
        "        Returns a tuple of:\n",
        "          - predictions: A numpy array of shape (N, ) of the predicted class per sample\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = None\n",
        "\n",
        "\n",
        "        # PUT YOUR CODE BELOW: Predict the classes of using the two-layer net.\n",
        "\n",
        "\n",
        "        # The lines below do not need to be changed in this method.\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def loss(self, scores, y_batch):\n",
        "        \"\"\"\n",
        "        Compute the loss using the cross_entropy_loss function and its\n",
        "        derivative: -1/np.sqrt(input_dim).\n",
        "        Inputs:\n",
        "        - scores: A numpy array of shape (N, C) containing a minibatch of N\n",
        "          data points; each point has dimension C, where C is the number of classes.\n",
        "        - y_batch: A numpy array of shape (N,) containing labels for the minibatch.\n",
        "\n",
        "        Returns: A tuple containing:\n",
        "        - loss as a single float\n",
        "        - gradient with respect to scores; an array of the same shape as W\n",
        "        \"\"\"\n",
        "        # The lines below do not need to be changed in this method.\n",
        "        return cross_entropy_loss(scores, y_batch)"
      ],
      "metadata": {
        "id": "dSr_3dSiYQOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Experiments\n",
        "\n",
        "Similar to the linear classifiers, you also want to identify the best configuration of hyperparameters that perform the best for your dataset. Similar to the case of the linear models, you can vary the learning rate for your solver. You should use the `Solver` class for these models as well. Use the `DATA` dictionary you defined previously as the data parameter.\n",
        "\n",
        "Additionaly, the neural network provides another hyperparameter to vary, the the number of neurons in the hidden layer.\n",
        "\n",
        "Adding a large of number of neurons may cause a large degradation in performance, the linear transformation scales as $O(N^3)$ with the number of neurons."
      ],
      "metadata": {
        "id": "yovrIeNablvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement a hyperparameter validation loop in the next cell to train multiple models with different hyperparameters. Keep the top-5 best performing models on the validation set. You may change learning rate, and hidden dims. You may change the num_epochs, but be wary of timeouts."
      ],
      "metadata": {
        "id": "N8zQgNiK-I9g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwZysCge-Js5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement the testing performance of your top-5 performing NN models on the test set and print the results. You can add additional cells below."
      ],
      "metadata": {
        "id": "zi1hTKxU-Kap"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QL6IbrNo-PTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#9658; Implement visualization for the `W1` weights of the *best* performing NN models. There are `hidden_dim` many of them per model. You should visualize a subset of the weights. You can select the columns at random.\n",
        "\n",
        "You can add additional cells below."
      ],
      "metadata": {
        "id": "qC8IL-RNdCOY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-CGHrOtdCb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}